\documentclass[a4paper, 11pt, ngerman]{article}
\usepackage{tikz-network}
\usepackage[left=3cm, right = 3cm, top=3cm, bottom=3cm, head=13.6pt]{geometry}
\usepackage{babel}
\usepackage[T1]{fontenc}
\usepackage{inputenc}
\usepackage[noend,nosemicolon,algoruled,noline]{algorithm2e}
\usepackage{amsmath}
\usepackage{amsthm}
\usepackage[nottoc,notlot,notlof]{tocbibind}
\usepackage{graphicx}
\usepackage{float}
\usepackage{enumitem}

\newcommand{\Aufgabe}{Aufgabe 3: Pancake Sort}
\newcommand{\TeilnahmeId}{67571}
\newcommand{\Name}{Finn Rudolph}

\usepackage{scrlayer-scrpage, lastpage}
\setkomafont{pageheadfoot}{\textrm}
\rohead{Teilnahme-ID: \TeilnahmeId}
\lohead{\Aufgabe}
\cfoot*{\thepage{}}

\title{\LARGE \textbf{Aufgabe 3: Pancake Sort}}
\author{\large Finn Rudolph \\ \\ \large Teilnahme-ID: 67571}
\date{\large 28. Dezember 2022}

\setlist[enumerate]{label*={\arabic*.}}

\begin{document}

\begin{titlepage}
    \maketitle
    \tableofcontents
    \thispagestyle{empty}
\end{titlepage}

\newtheorem{theorem}{Satz}
\newtheorem{lemma}{Lemma}
\theoremstyle{definition}
\newtheorem{definition}{Definition}

\section{Lösungsidee}

Pancake Sort ist ein bekannter Sortieralgorithmus, in seiner ursprünglichen Form wird der oberste Pfannkuchen allerdings nicht aufgegessen, sondern allein ein Präfix der zu sortierenden Folge umgekehrt. Pancake Sort wird daher auch als \emph{Sorting by Prefix Reversals} bezeichnet. Der Algorithmus wird zwar nicht direkt zum Sortieren verwendet, der mit ihm verbundene Pancake Graph dient jedoch beispielsweise als Grundlage für Netzwerke für parallele Computersysteme.

Ein Stapel von $n$ Pfannkuchen wird als Permutation
$$
    p = p_0, p_1, p_2, \dots, p_{n - 1}
$$
definiert, wobei $0 \le p_i \le n-1$ und $p_i \ne p_j$, für $0 \le i, j \le n-1$ und $i \ne j$. $p_0$ ist der oberste Pfannkuchen, $p_{n - 1}$ der unterste. Die Elemente von $p$ mit 0 beginnend zu indexieren und die $p_i$ bei 0 beginnen zu lassen, wird später einige Vereinfachungen bringen. Um eine Wende-und-Ess-Operation kompakt auszudrücken, wird der Wende-und-Ess-Operator $\gamma_i$ eingeführt.

\begin{definition}
    Sei $p$ eine Permutation von Länge $n$. Der Wende-und-Ess-Operator $\gamma_i$ ist für $p$ wie folgt definiert.
    $$
        \gamma_i p = p_{i-1}', p_{i-2}', \dots, p_1', p_0', p_{i+1}', p_{i+2}', \dots, p_{n-1}'
    $$
    $$
        p_j' = \begin{cases}
            p_j     & \text{wenn } p_j < p_i \\
            p_j - 1 & \text{wenn } p_j > p_i
        \end{cases}
        \quad 0 \le j \le n - 1, j \ne i
    $$
\end{definition}
$\gamma_i p$ bezeichnet also die Permutation der Länge $n - 1$, die man erhält, wenn die ersten $i+1$ Elemente von $p$ umgekehrt werden und anschließend das erste entfernt wird. Um tatsächlich eine Permutation der Länge $n - 1$ zu erhalten, werden durch $\gamma_i$ außerdem alle Elemente von $p$, die größer als $p_i$ sind, um 1 verkleinert. Das erhält die relative Ordung der Elemente, sodass die optimale Folge an Wende-und-Ess-Operationen unverändert bleibt. Zum Beispiel, wenn $p = 3, 0, 1, 2$, dann ist
$$
    \gamma_2 p = \gamma_2 (3, 0, 1, 2) = 0, 2, 1
$$
Um später das in Teilaufgabe a$)$ vorliegende Problem klar benennen zu können, wird ihm der Name ``$\gamma_i$-Pancake Sort'' gegeben. $I^n$ bezeichnet die identische Permutation der Länge $n$.

\begin{definition}[$\gamma_i$-Pancake Sort]
    Gegeben sei eine Permutation $p$ der ersten $n$ natürlichen Zahlen. Das Problem, eine kürzestmögliche Folge an $\gamma_i$-Operationen $\gamma_{i_0}, \gamma_{i_1}, \dots \gamma_{i_{k-1}}$ zu finden, sodass
    \begin{align*}
        (\gamma_{i_{k-1}} \dots (\gamma_{i_1} (\gamma_{i_0} p)) \dots) = I^{n - k}
    \end{align*}
    wird $\gamma_i$-Pancake Sort genannt. Das kleinstmögliche $k$ wird als $A(p)$ bezeichnet.
\end{definition}

\subsection{Der Pancake-Graph}

Im Kontext des ursprünglichen Pancake-Sort ist der sogenannte Pancake-Graph für Permutationen der Länge $n$ wie folgt definiert: Für jede Permutation der Länge $n$ gibt es genau einen Knoten, und zwischen den Knoten zweier Permutationen verläuft genau dann eine ungerichtete Kante, wenn sie durch das Umkehren eines Präfixes ineinander umgewandelt werden können. Analog dazu kann man einen Pancake-Graphen $G_n$ für das vorliegende Problem definieren: Jeder Permutation der Länge $n$ oder kleiner wird ein Knoten zugeordnet, und zwischen zwei Permutationen $p$ und $q$ wird eine von $p$ nach $q$ gerichtete Kante eingefügt, wenn $\gamma_i p = q$, für irgendein $0 \le i \le |p|-1$. $G_n$ ist also ein gerichteter, azyklischer Graph (DAG) mit $n$ ``Ebenen'', für jede Permutationslänge eine. Kanten verlaufen nur zur direkt folgenden Ebene, da $\gamma_i$ die Länge um genau 1 reduziert. In Abbildung 1 ist $G_4$ dargestellt, aufgrund seiner Größe wurde er auf 2 Seiten aufgeteilt und Knoten der kleinern Permutationen dupliziert. Die Knoten sind jeweils in lexikographischer Ordung von oben nach unten angeordnet. In diesem Abschnitt soll eine interessante Symmetrieeigenschaft von $G_n$ behandelt werden, die eine Optimierung der Lösungen für beide Teilaufgaben ermöglicht.

Betrachtet man die beiden Teile von $G_4$ gleichzeitig, fällt auf, dass der zweite Teil genau wie der erste Teil aussieht, nur vertikal gespiegelt. Auch die kleineren Pancake-Graphen $G_3, G_2$ und $G_1$, die Teilgraphen von $G_4$ sind, scheinen symmetrisch um ihre Mitte zu sein. Genauer sind die Kanten symmetrisch um die Mitte der lexikographisch sortierten Liste der Permutationen von Größe 4.

\newpage
\begin{tikzpicture}[node distance = {19mm}, main/.style = {draw, circle}]
    \node[main](0123) at (0, 0) {0123};
    \node[main](0132) [below of = 0123] {0132};
    \node[main](0213) [below of = 0132] {0213};
    \node[main](0231) [below of = 0213] {0231};
    \node[main](0312) [below of = 0231] {0312};
    \node[main](0321) [below of = 0312] {0321};

    \node[main](1023) [below of = 0321] {1023};
    \node[main](1032) [below of = 1023] {1032};
    \node[main](1203) [below of = 1032] {1203};
    \node[main](1230) [below of = 1203] {1230};
    \node[main](1302) [below of = 1230] {1302};
    \node[main](1320) [below of = 1302] {1320};

    \node[main](012) at (7, -5.8) {012};
    \node[main](021) [below of = 012] {021};
    \node[main](102) [below of = 021] {102};
    \node[main](120) [below of = 102] {120};
    \node[main](201) [below of = 120] {201};
    \node[main](210) [below of = 201] {210};

    \node[main](01) at (11, -9.6) {01};
    \node[main](10) [below of = 01] {10};

    \node[main](0) at (13.5, -10.5) {0};

    \draw[->](0123) -- (012);
    \draw[->](0123) -- (102);
    \draw[->](0123) -- (210);

    \draw[->](0132) -- (021);
    \draw[->](0132) -- (102);
    \draw[->](0132) -- (210);

    \draw[->](0213) -- (102);
    \draw[->](0213) -- (012);
    \draw[->](0213) -- (120);

    \draw[->](0231) -- (120);
    \draw[->](0231) -- (021);
    \draw[->](0231) -- (201);
    \draw[->](0231) -- (210);

    \draw[->](0312) -- (201);
    \draw[->](0312) -- (012);
    \draw[->](0312) -- (120);

    \draw[->](0321) -- (210);
    \draw[->](0321) -- (021);
    \draw[->](0321) -- (201);
    \draw[->](0321) -- (120);

    \draw[->](1023) -- (012);
    \draw[->](1023) -- (201);

    \draw[->](1032) -- (021);
    \draw[->](1032) -- (012);
    \draw[->](1032) -- (201);

    \draw[->](1203) -- (102);
    \draw[->](1203) -- (021);

    \draw[->](1230) -- (120);
    \draw[->](1230) -- (210);

    \draw[->](1302) -- (201);
    \draw[->](1302) -- (102);
    \draw[->](1302) -- (021);

    \draw[->](1320) -- (210);
    \draw[->](1320) -- (120);

    \draw[->](012) -- (01);
    \draw[->](012) -- (10);
    \draw[->](021) -- (10);
    \draw[->](021) -- (01);
    \draw[->](102) -- (01);
    \draw[->](120) -- (10);
    \draw[->](201) -- (01);
    \draw[->](201) -- (10);
    \draw[->](210) -- (01);
    \draw[->](210) -- (10);

    \draw[->](01) -- (0);
    \draw[->](10) -- (0);
\end{tikzpicture}
\newpage
\begin{tikzpicture}[node distance = {19mm}, main/.style = {draw, circle}]
    \node[main](2013) at (0, 0) {2013};
    \node[main](2031) [below of = 2013] {2031};
    \node[main](2103) [below of = 2031] {2103};
    \node[main](2130) [below of = 2103] {2130};
    \node[main](2301) [below of = 2130] {2301};
    \node[main](2310) [below of = 2301] {2310};

    \node[main](3012) [below of = 2310] {3012};
    \node[main](3021) [below of = 3012] {3021};
    \node[main](3102) [below of = 3021] {3102};
    \node[main](3120) [below of = 3102] {3120};
    \node[main](3201) [below of = 3120] {3201};
    \node[main](3210) [below of = 3201] {3210};

    \node[main](012) at (7, -5.8) {012};
    \node[main](021) [below of = 012] {021};
    \node[main](102) [below of = 021] {102};
    \node[main](120) [below of = 102] {120};
    \node[main](201) [below of = 120] {201};
    \node[main](210) [below of = 201] {210};

    \node[main](01) at (11, -9.6) {01};
    \node[main](10) [below of = 01] {10};

    \node[main](0) at (13.5, -10.5) {0};

    \draw[->](2013) -- (012);
    \draw[->](2013) -- (102);

    \draw[->](2031) -- (021);
    \draw[->](2031) -- (120);
    \draw[->](2031) -- (201);

    \draw[->](2103) -- (102);
    \draw[->](2103) -- (012);

    \draw[->](2130) -- (120);
    \draw[->](2130) -- (201);

    \draw[->](2301) -- (201);
    \draw[->](2301) -- (210);
    \draw[->](2301) -- (021);

    \draw[->](2310) -- (210);
    \draw[->](2310) -- (021);

    \draw[->](3012) -- (012);
    \draw[->](3012) -- (201);
    \draw[->](3012) -- (021);
    \draw[->](3012) -- (102);

    \draw[->](3021) -- (021);
    \draw[->](3021) -- (210);
    \draw[->](3021) -- (102);

    \draw[->](3102) -- (102);
    \draw[->](3102) -- (201);
    \draw[->](3102) -- (021);
    \draw[->](3102) -- (012);

    \draw[->](3120) -- (120);
    \draw[->](3120) -- (210);
    \draw[->](3120) -- (102);

    \draw[->](3201) -- (201);
    \draw[->](3201) -- (120);
    \draw[->](3201) -- (012);

    \draw[->](3210) -- (210);
    \draw[->](3210) -- (120);
    \draw[->](3210) -- (012);

    \draw[->](012) -- (01);
    \draw[->](012) -- (10);
    \draw[->](021) -- (10);
    \draw[->](021) -- (01);
    \draw[->](102) -- (01);
    \draw[->](120) -- (10);
    \draw[->](201) -- (01);
    \draw[->](201) -- (10);
    \draw[->](210) -- (01);
    \draw[->](210) -- (10);

    \draw[->](01) -- (0);
    \draw[->](10) -- (0);
\end{tikzpicture}
\begin{figure}
    \caption{Der Pancake-Graph $G_4$. Von Knoten $u$ verläuft genau dann eine gerichtete Kante nach Knoten $v$, wenn die zu $u$ zugehörige Permutation durch ein $\gamma_i$ in die zu $v$ zugehörige Permutation umgewandelt werden kann.}
\end{figure}
\newpage

Wenn man $G_4$ an einem Stück ohne Duplikation von Knoten zeichnen würde, wäre tatsächlich der gesamte Graph achsensymmetrisch um seine Mitte. Dass die Symmetrie bei $G_1, G_2, G_3$ und $G_4$ auftritt, lässt vermuten, dass sie für $G_n$, mit $n \ge 1$, allgemein gilt.
Bei genauerer Betrachtung des Effekts von $\gamma_i$ auf zwei zur Mitte symmetrisch liegende Permutationen fällt noch eine stärkere Eigenschaft auf. Wir betrachten als Beispiel die zwei symmetrisch liegenden Permutationen $p = 0,2,3,1$ und $p^* = 3, 1, 0, 2$:
\begin{align*}
    \gamma_0 p = 1, 2, 0 \quad \gamma_0 p^* = 1, 0, 2 \\
    \gamma_1 p = 0, 2, 1 \quad \gamma_1 p^* = 2, 0, 1 \\
    \gamma_2 p = 2, 0, 1 \quad \gamma_2 p^* = 0, 2, 1 \\
    \gamma_3 p = 2, 1, 0 \quad \gamma_3 p^* = 0, 1, 2
\end{align*}
Die Ergebnisse der jeweiligen Anwendung von $\gamma_i$ liegen symmetrisch um die Mitte der Liste aller Permutationen von Länge 3. Mithilfe des Programms \emph{test\_sym.cpp} konnte diese Eigenschaft von $\gamma_i$ für alle symmetrisch gelegenen Paare an Permutationen bis Größe 10 bestätigt werden. Es scheint also, dass die Symmetrie des Pancake-Graphen allgemein gültig ist.

Um diese Vermutung zu beweisen, sind einige weitere Mittel nötig. Zunächst wird das fakultätsbasierte Zahlensystem eingeführt, mithilfe dessen der Effekt des $\gamma_i$-Operators aus einer völlig anderen Perspektive betrachtet werden kann. Denn das fakultätsbasierte Zahlensystem erlaubt es, die Anzahl an Inversionen symmetrisch gelegener Paare von Permutationen miteinander in Verbindung zu bringen. Damit kann schließlich gezeigt werden, dass die Anwendung von $\gamma_i$ auf zwei in einer lexikographisch sortierten Liste symmetrisch positionierte Permutationen wieder zu einem symmetrischen Paar führt.
\bigskip

\noindent \emph{Das fakultätsbasierte Zahlensystem.} Im fakultätsbasierten Zahlensystem wird im Gegenstz zum Dezimal- oder Binärsystem eine unterschiedliche Basis für jede Ziffer verwendet. Die $k$-te Ziffer (mit 0 beginnend), von rechts gelesen, verwendet $k!$ als Basis und kann die Werte 0 bis $k$ annehmen. Der Wert einer fakultätsbasiert geschriebenen Zahl ist die Summe der einzelnen Ziffern, multipliziert mit ihrer jeweiligen Basis. Beispielsweise ist
\begin{align*}
    17_{10} & = 2210_!   = 2 \cdot 3! + 2 \cdot 2! + 1 \cdot 1! + 0 \cdot 0!             \\
    24_{10} & = 10000_! = 1 \cdot 4! + 0 \cdot 3! + 0 \cdot 2! + 0 \cdot 1! + 0 \cdot 0! \\
    23_{10} & = 3210_!  = 3 \cdot 3! + 2 \cdot 2! + 1 \cdot 1! + 0 \cdot 0!
\end{align*}
wobei das tiefgestellte ! auf das fakultätsbasierte Zahlensystem hinweist. Eine Fakultät $n!$, geschrieben im fakultätsbasierten Zahlensystem, ist immer von der Form $1000\dots$ ($n$ Nullen). Die Ziffern von $n! - 1$ sind immer genau $n-1, n-2, n-3, \dots, 0$.
Da sich mit einer fakultätsbasierten Zahl mit $n$ Ziffern genau $n!$ Zahlen darstellen lassen, können diese Zahlen auf natürlichem Weg zum Nummerieren von Permutationen der Länge $n$ verwendet werden. Folgende zwei Arten der Nummerierung sind entscheidend den Beweis der Symmetrie des Pancake-Graphen. Beide bilden eine Bijektion zwischen Permutationen der Länge $n$ und ganzen Zahlen von 0 bis $n! - 1$.

\begin{definition}
    Mit $\mu(p)$ wird der Index der Permutation $p$ in einer \emph{lexikographisch aufsteigend} sortierten Folge aller Permutationen der Länge $|p|$ bezeichnet. Mit $\mu(p)_i$ wird die $i$-te Ziffer (beginnend von links) von $\mu(p)$, geschrieben im fakultätsbasierten Zahlensystem, bezeichnet.
\end{definition}

$\mu(p)$ ist auch als Lehmer-Code von $p$ bekannt \cite{factorial}.

\begin{definition}
    Mit $\nu(p)$ wird der Index der Permutation $p$ in einer \emph{kolexikographisch absteigend} sortierten Folge aller Permutationen der Länge $|p|$ bezeichnet. Mit $\nu(p)_i$ wird die $i$-te Ziffer (beginnend von links) von $\nu(p)$, geschrieben im fakultätsbasierten Zahlensystem, bezeichnet.
\end{definition}

Bei Sortierung nach kolexikographischer Ordung werden die Permutationen von rechts anstatt von links beginnend verglichen \cite{lexicographic}.

Für $\mu(p)$ und $\nu(p)$ gelten folgende Eigenschaften: $\mu(p)_i$ ist genau die Anzahl an kleineren Elementen rechts von $p_i$, und $\nu(p)_{|p| - i - 1}$ die Anzahl an größeren Elementen links von $p_i$ \cite{factorial}. Mit $\mu(p)$ ist es nun möglich, die zu $p$ symmetrisch gelegene Permutation zu definieren.

\begin{definition}
    Sei $p$ eine Permutation der Länge $n$. $p^*$ bezeichnet die Permutation, sodass $\mu(p) = n! - \mu(p^*) - 1$.
\end{definition}

$p$ und $p^*$ werden auch als symmetrisches Paar von Permutationen bezeichnet. Zum Beweis der Symmetrie von $G_n$ soll gezeigt werden, dass $\mu(\gamma_i p) + \mu(\gamma_i p^*) = (n - 1)! - 1$ ist. Denn daraus folgt direkt, dass $\gamma_i p$ und $\gamma_i p^*$ wieder ein symmetrisches Paar von Permutationen ist. Die Strategie ist, zunächst zu zeigen, dass wenn ein Präfix zweier symmetrisch gelegener Permutationen umgekehrt wird, wieder zwei symmetrisch gelegene Permutationen entstehen. Dafür wird allerdings noch folgendes Lemma benötigt.

\begin{lemma}
    Sei $p$ eine Permutation der Länge $n$ und $p_i$ ein Element von $p$ $(0 \le i \le n - 1)$. Für jedes $0 \le j \le n-1, j \ne i$ ist entweder ($p_i < p_j$ und $p^*_i > p^*_j$) oder ($p_i > p_j$ und $p^*_i < p^*_j$).
\end{lemma}

\begin{proof}
    In anderen Worten sagt Lemma 1, dass die kleineren, rechts bzw. links gelegenen Elemente von $p_i$ und $p^*_i$ alle an unterschiedlichen Positionen liegen. Für jede Position $j$ ist also entweder $p_i$ und $p_j$ oder $p^*_i$ und $p^*_j$ eine Inversion. Zunächst soll eine etwas schwächere Eigenschaft gezeigt werden, die für den Beweis nötig ist.

    Aufgrund der Definition von $p^*$ gilt
    \begin{align*}
        \mu(p) + \mu(p^*) & = n! - 1                                                                           \\
                          & =(n - 1) \cdot (n - 1)! + (n - 2) \cdot (n - 2)! + \dots + 1 \cdot 1! + 0 \cdot 0!
    \end{align*}
    Die Koeffizienten der Fakultäten in der zweiten Zeile sind genau die Ziffern von $\mu(p) + \mu(p^*)$ in fakultätsbasierter Schreibweise, daher gilt
    \begin{align*}
        \mu(p)_i + \mu(p^*)_i = n - i - 1 \quad 0 \le i \le n - 1
    \end{align*}
    Ist das nicht der Fall, ist es leicht zu überprüfen, dass $\mu(p) + \mu(p^*) \ne n! - 1$. Daher muss die Anzahl an kleineren, rechts gelgenen Elementen von $p_i$ plus der Anzahl an kleineren, rechts gelegenen Elementen von $p^*_i$ genau $n-i-1$ sein. Mit ähnlicher Begründung kann gezeigt werden, dass $\nu(p)_i + \nu(p^*)_i = i$, folglich ist die Anzahl an größeren, links gelegenen Elementen von $p_i$ plus der Anzahl an größeren, links gelegenen Elementen von $p^*_i$ genau $i$. Die Anzahl an links gelegenen, größeren und rechts gelegenen, kleineren Elementen von $p_i$ und $p^*_i$ zusammengezählt ist also allein anbhängig von $i$ und unabhängig davon, welche Permutation $p$ ist.

    Nun wird der eigentliche Beweis durchgeführt, er funktioniert über unendlichen Abstieg. Man nehme an, dass für irgendein $j_0 > i$ sowohl $p_{j_0} < p_i$, als auch $p^*_{j_0} < p^*_i$ gilt. Der Fall $j_0 < i$ funktioniert ähnlich. Auch die Annahme $p_{j_0} < p_i$ und $p^*_{j_0} < p^*_i$ dient nur der einfacheren Beweisführung, der Fall $p_{j_0} > p_i$ und $p^*_{j_0} > p^*_i$ kann mit der gleichen Methode bewiesen werden. Da $\nu(p)_{n - j_0 - 1} + \nu(p^*)_{n - j_0 - 1} = j_0$, muss für irgendein ein $j_1 < j_0$ gelten, dass $p_{j_1} < p_{j_0}$ und $p^*_{j_1} < p^*_{j_0}$. Andernfalls wäre es nicht möglich, auf insgesamt $j_0$ links gelegene, größere Elemente von $p_{j_0}$ und $p^*_{j_0}$ zu kommen. Nun gibt es zwei Fälle:
    \begin{enumerate}
        \item $j_1 < i$: Rechts von $j_1$ liegen $i$ und $j_0$, das heißt, es muss zwei Indizes $j_2, j_3 > j_1$ geben, sodass $p_{j_2} < p_{j_1}$ und $p^*_{j_2} < p^*_{j_1}$, $p_{j_3} < p_{j_1}$ und $p^*_{j_3} < p^*_{j_1}$. Andernfalls wäre es wieder nicht möglich, auf die nötigen $\mu(p)_{j_1} + \mu(p^*)_{j_1} = n - j_1 - 1$ nötigen, kleineren, rechts gelegenen Elemente zu kommen. Denn bereits zwei der $n - j_1 - 1$ rechts gelegenen Plätze sind sowohl in $p$ als auch in $p^*$ durch größere Zahlen besetzt, aber $n - j_1 - 1$ kleinere Elemente sind erforderlich.
        \item $i < j_1 < j_0$: Da $p_{j_1} < p_{j_0}$ und $p^*_{j_1} < p^*_{j_0}$, muss es rechts von $j_1$ einen Index $j_2 > j_1$ geben, sodass $p_{j_2} < p_{j_1}$ und $p^*_{j_2} < p^*_{j_1}$. Auch links von $j_1$ muss es einen Index $j_3 < j_1$ geben, sodass $p_{j_3} < p_{j_1}$ und $p^*_{j_3} < p^*_{j_1}$. Erneut wäre andernfalls das Erreichen der nötigen $\mu(p)_{j_1} + \mu(p^*)_{j_1} = n - j_1 - 1$ rechts gelegenen, kleineren und der $\nu(p)_{n - j_1 - 1} + \nu(p^*)_{n - j_1 - 1} = j_1$ links gelegenen, größeren Elemente unmöglich.
    \end{enumerate}
    Man sieht, dass durch die Forderung nach einer allein vom Index anbhängigen Zahl rechts gelegener, kleinerer bzw. links gelegener, größerer Elemente immer kleinere Zahlen in $p$ und $p^*$ gezwungen werden. Um diese herum sind aber nur größere Elemente, wodurch wieder kleinere Zahlen zum Ausgleich nötig werden. Dieser Prozess endet niemals, da mit jedem Schritt immer noch kleinere Zahlen erzeugt werden. Das ist ein Widerspruch, da natürliche Zahlen, wie sie in einer Permutation vorkommen, nicht unendlich oft verringert werden können. Das zeigt, dass die Annahme $p_{j_0} < p_i$ und $p^*_{j_0} < p^*_i$ falsch war.
\end{proof}

Für eine Permutation $p$ und $0 \le i, j, k \le n - 1$ wird nun die Funktion $\eta(p, i, j, k)$ definiert.
$$
    \eta(p, i, j, k) = \sum_{h = j}^k
    \begin{cases}
        1 & \text{wenn } p_i > p_h   \\
        0 & \text{wenn } p_i \le p_h
    \end{cases}
$$
$\eta(p, i, j, k)$ zählt die Anzahl an Elementen mit Indizes in $[j, k]$, die kleiner als $p_i$ sind. Lemma 1 ermöglicht es, die Summe von $\eta$ für $p$ und $p^*$ einfach zu berechnen, denn für jeden Index ist entweder das Element in $p$ oder in $p^*$ kleiner als $p_i$ bzw. $p^*_i$.
\begin{align*}
    \eta(p, i, j, k) + \eta(p^*, i, j, k) & = \sum_{h = j}^k
    \begin{cases}
        1 & \text{wenn } p_i > p_h   \\
        0 & \text{wenn } p_i \le p_h
    \end{cases} + \sum_{h = j}^k
    \begin{cases}
        1 & \text{wenn } p^*_i > p^*_h   \\
        0 & \text{wenn } p^*_i \le p^*_h
    \end{cases}                                 \\
                                          & = \sum_{h = j}^k \Bigg (
    \begin{cases}
            1 & \text{wenn } p_i > p_h   \\
            0 & \text{wenn } p_i \le p_h
        \end{cases} +
    \begin{cases}
            1 & \text{wenn } p^*_i > p^*_h   \\
            0 & \text{wenn } p^*_i \le p^*_h
        \end{cases} \Bigg )                                 \\
                                          & = \sum_{h = j}^k 1       \\
                                          & = k - j + 1
\end{align*}
Damit kann nun gezeigt werden, dass das Umkehren von Präfixen zweier symmetrisch gelegener Permutationen erneut zu zwei symmetrisch gelegene Permutationen führt. Das ist fast das gewünschte Ergebnis, es muss lediglich noch das erste Element aus beiden Permutationen entfernt werden.
\begin{lemma}Seien $x$ und $y$ die Permutationen, die aus $p$ und $p^*$ durch Umkehrung des Präfixes bis einschließlich Index $i$ hervorgehen. Wenn $\mu(p) + \mu(p^*) = n! - 1$, dann gilt auch $\mu(x) + \mu(y) = n! - 1$.
\end{lemma}

\begin{proof}
    Die Ziffern $\mu(p)$ und $\mu(p^*)$ geben in fakultätsbasierter Schreibweise die Anzahl an rechts gelegenen, kleineren Elementen an. Da an den Elementen $p_j, p^*_j$ für $j > i$ nichts geändert wird, ändert sich auch nicht ihre Zahl rechts gelegener, kleinerer Elemente, d. h. sie können im Folgenden außer Acht gelassen werden. Für $j < i$ werden alle links gelegenen, kleineren Elemente durch die Umkehrung auf die rechte Seite gebracht, die kleineren Elemente rechts von $i$ bleiben. Der Index, zu dem das $j$-te Element durch die Umkehrung bewegt wird, ist $i - j$. Folglich ist die Anzahl rechts gelegener, kleinerer Elemente von $x_{i - j}$ und $y_{i - j}$ zusammen
    \begin{align*}
        \mu(x)_{i - j} + \mu(y)_{i - j}
         & =  \eta(p, j, 0, j - 1) + \eta(p, j, i + 1, n - 1)            \\
         & \quad + \eta(p^*, j, 0, j - 1) + \eta(p^*, j, i + 1, n - 1)   \\
         & =  \eta(p, j, 0, j - 1) + \eta(p^*, j, 0, j - 1)              \\
         & \quad + \eta(p, j, i + 1, n - 1) + \eta(p^*, j, i + 1, n - 1) \\
         & =  (j - 1 - 0 + 1) + (n - 1 - (i + 1) + 1)                    \\
         & =  j + n - i - 1                                              \\
         & =  n - (i - j) - 1
    \end{align*}
    Daraus folgt
    \begin{align*}
        \mu(x)_i + \mu(y)_i = n - i - 1 \quad 0 \le i \le n - 1
    \end{align*}
    und damit
    \begin{align*}
        \mu(x) + \mu(y) = n! - 1
    \end{align*}
\end{proof}

Man sieht, dass das Umkehren eines Präfixes in einem symmetrischen Paar von Permutationen wieder zu einem symmetrischen Paar führt. Nun kann die Symmetrie des Pancake-Graphen, bzw. des $\gamma_i$-Operators als Satz festgehalten werden.

\begin{theorem}
    Wenn $p$ eine Permutation der Länge $n$ und $q$ eine Permutation der Länge $n - 1$ ist, gilt
    $$
        \gamma_i p = q \Longleftrightarrow \gamma_i p^* = q^* \quad 0 \le i \le n - 1
    $$
\end{theorem}

\begin{proof}
    Wir nennen die Permutation, die man durch Umkehren des Präfixes bis $i$ von $p$ erhält, $x$. Aufgrund von Lemma 2 ist $x^*$ genau die Permutation, die man durch Umkehren des Präfixes bis $i$ von $p^*$ erhält.
    Da
    \begin{align*}
        \gamma_i p = x_1, x_2, \dots, x_{n-1} \\
        \gamma_i p^* = x^*_1, x^*_2, \dots, x^*_{n-1}
    \end{align*}
    entspricht die Anzahl rechts gelegener, kleinerer Elemente von $(\gamma_i p)_0, (\gamma_i p)_1, \dots, (\gamma_i p)_{n - 2}$ bzw. $(\gamma_i p^*)_0, (\gamma_i p^*)_1, \dots, (\gamma_i p^*)_{n - 2}$ genau der Anzahl rechts gelegener, kleinerer Elemente von $x_1, x_2, \dots, x_{n-1}$ bzw. $x^*_1, x^*_2, \dots, x^*_{n-1}$. Daher gilt
    \begin{align*}
        \mu(\gamma_i p)_i = \mu(x)_{i + 1} \\
        \mu(\gamma_i p^*)_i = \mu(x^*)_{i + 1}
    \end{align*}
    und folglich
    \begin{align*}
        \mu(\gamma_i p)_i + \mu(\gamma_i p^*)_i & = \mu(x)_{i + 1} + \mu(x^*)_{i + 1} \\
                                                & = (n - (i + 1) - 1)                 \\
                                                & = (n - 1) - i - 1
    \end{align*}
    Da $|\gamma_i p| = |\gamma_i p^*| = n - 1$, ist $\gamma_i p$ und $\gamma_i p^*$ ein symmetrisches Paar von Permutationen der Länge $n - 1$. Somit gilt $\gamma_i p = q$ genau dann, wenn $\gamma_i p^* = q^*$.
\end{proof}

\subsection{Reduktion des Burnt Pancake-Problems}

In diesem Abschnitt soll gezeigt werden, dass $\gamma_i$-Pancake Sort mindestens so schwierig wie das Burnt Pancake Problem, eine Variante des Pfannkuchen-Sortierproblems, ist. Mit ``mindestens so schwierig'' ist gemeint, dass das Burnt Pancake Problem in polynomieller Zeit auf das vorliegende Problem reduziert werden kann. Damit wird gezeigt, dass wahrscheinlich kein Algorithmus existiert, der $\gamma_i$-Pancake Sort in polynomieller Zeit löst. Für das Burnt Pancake-Problem gibt es zwar keinen Beweis der NP-Schwere, allerdings ist es seit über 40 Jahren niemandem gelungen, einen Algorithmus mit polynomieller Laufzeit für dieses Problem zu entwickeln.

Im Burnt Pancake Problem haben Pfannkuchen eine verbrannte Seite, die nach dem Sortieren bei jedem Pfannkuchen unten liegen muss \cite{burntpancakes}. Das Konzept der verbrannten Seite wird in folgender Definition durch ein Vorzeichen vor jedem Element der Permutation formalisiert.
\begin{definition}[Burnt Pancake-Problem]
    Gegeben sei eine vorzeichenbehaftete Permutation
    \begin{align*}
        p = \sigma_0 p_0, \sigma_1 p_1, \dots, \sigma_{n-1} p_{n-1}
    \end{align*}
    wobei $0 \le p_i \le n-1$ und $\sigma_i \in \{-1, 1\}$ für $0 \le i \le n - 1$ sowie $p_i \ne p_j$ für $i \ne j$. Wir nennen folgendes Problem das Burnt Pancake-Problem: Was ist die minimale Anzahl an Präfixumkehrungen, wobei bei einer Präfixumkehrung auch alle Vorzeichen im umgekehrten Präfix invertiert werden, sodass $p$ in $I^n$ überführt wird und alle Vorzeichen positiv sind?
\end{definition}
$\sigma_i = -1$ bedeutet, dass der $i$-te Pfannkuchen die verbrannte Seite oben hat, andernfalls liegt die unverbrannte Seite oben.

\begin{theorem}
    $\gamma_i$-Pancake Sort ist mindestens so schwierig wie das Burnt Pancake-Problem.
\end{theorem}

\begin{proof}
    Schon das Bestimmen der minimalen Anzahl an $\gamma_i$-Operationen ist mindestens so schwierig wie das Burnt Pancake-Problem, was im Beweis gezeigt wird. Daraus folgt direkt, dass auch $\gamma_i$-Pancake Sort mindestens so schwierig ist, denn mit jedem Algorithmus, der $\gamma_i$-Pancake Sort löst, kann man einfach die minimale Anzahl an $\gamma_i$-Operationen bestimmen.

    Die Reduktion geschieht nun, indem das Burnt Pancake-Problem in $\gamma_i$-Pancake Sort simuliert wird. Für eine vorzeichenbehaftete Permutation $p$ der Länge $n$, die Eingabe für das Burnt Pancake-Problem, konstruieren wir eine nicht-vorzeichenbehaftete Permutation $q$ wie folgt:
    $$
        q = a_0, a_1, \dots, a_{n-1}
    $$
    $$
        a_i  = \begin{cases}
            (p_i - 1) \cdot 3n + 1, (p_i - 1) \cdot 3n + 2, \dots, p_i \cdot 3n & \text{wenn } \sigma_i = 1  \\
            p_i \cdot 3n, p_i \cdot 3n - 1, \dots, (p_i - 1) \cdot 3n + 1       & \text{wenn } \sigma_i = -1
        \end{cases}
    $$
    Jedem Pfannkuchen in $p$ wird je nach seiner Orientierung eine aufsteigende oder absteigende Folge von $3n$ aufeinanderfolgenden, natürlichen Zahlen zugeordnet. Dieses Vorgehen ist in Abbildung 2 veranschaulicht. Mit $a_i$ wird die zu $p_i$ zugehörige Teilfolge von $q$ bezeichnet. Der Einfachheit halber bezeichnet $a_i$ auch die zu $p_i$ zugehörige Teilfolge in $q$ nach einigen Sortierschritten, auch wenn diese dann andere Zahlen enthalten kann bzw. gekürzt worden sein kann. Die Folgen $a_0, a_1, \dots, a_{n-1}$ in Zeile 1 werden zu einer Folge $q$ zusammengefügt, $q$ ist also keine Folge von Folgen. Die Länge von $q$ beträgt $n \cdot 3n = 3n^2$, ist also durch ein Polynom in $n$ beschränkt, d. h. die Reduktion ist eine Polynomialzeitreduktion.

    \begin{figure}[h]
        \centering
        \includegraphics[width=\textwidth]{grafiken/burnt-pancake-reduktion-1}
        \caption{Reduktion des Burnt Pancake-Problems auf $\gamma_i$-Pancake Sort. Die Pfeile geben die Orientierung der verbrannten Pfannkuchen an, die Pfeilspitze zeigt zur nicht verbrannten Seite.}
    \end{figure}
    Ist $\sigma_i = 1$, d. h. der $i$-te Pfannkuchen ist richtig orientiert, wird er durch eine aufsteigende Folge repräsentiert. Das entspricht auch der richtigen Orientierung im Sortieren ohne Vorzeichen. Denn wäre $p$ vollständig sortiert und $\sigma_i = 1$ für alle $0 \le i \le n - 1$, wäre auch $q$ vollständig sortiert. Die Idee ist nun, zu zeigen, dass kein $a_i$ in einer optimalen Folge an $\gamma_i$-Operationen in der Mitte getrennt oder vollständig aufgegessen wird. Denn dann werden durch $\gamma_i$-Operationen immer nur Pfannkuchen am Anfang und Ende einer der Folgen $a_i$ entfernt, sodass sich diese schließlich wie ein verbrannter Pfannkuchen verhalten. Durch die $3n$ Pufferelemente bleiben von jedem $a_i$ außerdem mindestens $n$ Elemente übrig, sodass das Ergebnis des Sortierens mit $\gamma_i$ als sortierter Stapel an verbrannten Pfannkuchen interpretiert werden kann.

    Die einem Element von $p$ zugeordnete Teilfolge von $q$ wird niemals durch eine optimale Folge an $\gamma_i$-Operationen vollständig entfernt, da eine vorzeichenbehaftete Permutation in maximal $2n$ Schritten sortiert werden kann. Diese obere Schranke stammt von Cohen und Blum \cite{burntpancakes}. Für $n \ge 10$ wurde dort sogar eine Schranke von $2n - 2$ angegeben, der Einfachheit halber wird im Folgenden allerdings mit $2n$ gearbeitet. Es folgt, dass eine Folge an $\gamma_i$-Operationen, die länger als $2n$ ist, nicht optimal sein kann, denn man könnte $q$ in maximal $2n$ Schritten sortieren, indem man eine optimale Folge an Präfixumkehrungen für $p$ simuliert. Wenn in $p$ das Präfix bis Index $i$ umgekehrt wird, wendet man $\gamma_j$ auf $q$ an, wobei $j$ die größtmöglich Zahl ist, sodass $q_j$ zur Teilfolge von $p_i$ gehört (unter Beachtung der Tatsache, dass durch jede Anwendung von $\gamma_i$ möglicherweise einige Elemente in $q$ verringert werden). Da jedes Element von $p$ nach der Sortierung positiv ist, sind nach der Definition von $q$ auch alle den Elementen von $p$ zugeordneten Teilfolgen aufsteigend sortiert. Da die Pfannkuchen in $p$ aufsteigend sortiert sind, sind auch die ihnen zugeordneten Teilfolgen in $q$ aufsteigend sortiert, daher lässt sich $q$ tatsächlich in maximal $2n$ Schritten sortieren. Da also maximal $2n$ $\gamma_i$-Operationen durchgeführt werden und mit jeder $\gamma_i$-Operation genau ein Element aus $q$ entfernt wird, muss jedes $a_i$ nach dem Sortieren noch mindestens $n$ Elemente enthalten.

    Nun wird gezeigt, dass es unter den optimalen $\gamma_i$-Folgen zum Sortieren von $q$ immer eine gibt, die im Sortierprozess keines der $a_i$ in der Mitte trennt. Das ist notwendig, da ein solcher Schritt, übertragen auf das Burnt Pancake-Problem, unmöglich wäre. Man nehme an, $a_j$ für $0 \le j \le n - 1$ wird durch $\gamma_k$ mit $l + 1 \le k \le r-1$ in zwei Teile geteilt, wobei $a_j$ vor der Anwendung von $\gamma_k$ in $q$ von $q_l$ bis $q_r$ reichte. Da nach vollständiger Sortierung von $q$ noch Elemente von $a_j$ vorhanden sein müssen, müssen die zwei Teile an einem bestimmten Punkt wieder in richtiger Orientierung zusammengefügt werden. Es ergeben sich zwei Fälle: Entweder wurde einer der Teile vollständig aufgegessen oder beide sind noch vorhanden. Dass beide Teile vollständig aufgegessen werden ist unter der Annahme, dass die behandelte $\gamma_i$-Folge optimal ist, unmöglich. Das Ergebnis im ersten Fall wäre auch erreichbar, indem man immer wieder Elemente vom Anfang oder Ende von $a_j$ entfernt. Im zweiten Fall hätte man anstatt $\gamma_k$ $\gamma_r$ verwenden können und zum gleichen Ergebnis gelangen können, indem man $q_{k + 1}, q_{k + 2}, \dots, q_r$ dauerhaft mit $q_l, q_{l+1}, \dots, q_{k}$ mitführt. Das heißt, man führt alle Wendeoperationen hinter den gleichen $a_i$ wie zuvor durch, behandelt $q_l, q_{l+1}, q_r$ aber genau so wie zuvor $q_l, q_{l+1}, q_{k-1}$. Der genaue Index der $\gamma_i$-Operationen mag sich unterscheiden, da in jedem Schritt aber die gleichen $a_i$ umgekehrt werden, ist das Ergebnis ebenfalls ein sortierter Stapel. Die Argumentation ist in Abbildung 3 veranschaulicht. Durch die Veränderung wird die Gesamtzahl an $\gamma_i$-Operationen nicht vergrößert, daher gibt es immer eine optimale Folge an $\gamma_i$-Operationen ohne Trennung einer Folge $a_i$ in der Mitte.

    \begin{figure}[H]
        \centering
        \includegraphics[width=\textwidth]{grafiken/burnt-pancake-reduktion-2}
        \caption{Eine optimale Folge an $\gamma_i$-Operationen kann immer ohne die Teilung von $a_i$ in der Mitte auskommen.}
    \end{figure}

    Damit verhält sich eine Teilfolge, die einem verbrannten Pfannkuchen zugeordnet wurde, im Sortierprozess wie ein verbrannter Pfannkuchen. Denn sie kann weder vollständig verschwinden oder geteilt werden und muss am Ende, wie der verbrannte Pfannkuchen, richtig orientiert an der richtigen Stelle platziert sein, damit $q$ sortiert ist. Folglich ist die minimale Anzahl an $\gamma_i$-Operationen zum Sortieren von $q$ gleich der minimalen Anzahl an Wendeoperationen zum Sortieren von $p$. Da jede Instanz des Burnt Pancake-Problems in polynomieller Zeit auf eine Instanz von $\gamma_i$-Pancake Sort reduziert werden kann, ist $\gamma_i$-Pancake Sort mindestens so schwierig wie das Burnt Pancake-Problem.
\end{proof}

\subsection{Finden der kürzesten Folge an $\gamma_i$-Operationen}

In diesem Abschnitt werden drei Lösungsverfahren für Teilaufgabe a) entwickelt. Zunächst wird ein Brute-Force Ansatz vorgestellt, der bereits alle vorgegebenen Beispiele gut lösen kann. Anschließend wird eine untere Schranke für die nötige Anzahl an $\gamma_i$-Operationen zum Erreichen einer identischen Permutation hergeleitet, mit der sich der Brtue-Force Algorithmus auf zwei Arten verbessern lässt.
\bigskip

\noindent \emph{Brute-Force Lösung.} Wie der Name bereits sagt, werden einfach alle Möglichkeiten, eine $\gamma_i$-Operation durchzuführen, ausgetestet, also $\gamma_0, \gamma_1, \dots, \gamma_{n-1}$. Wir definieren eine Warteschlange $Q$, die alle noch nicht besuchten Permutationen enthält, die von einer besuchten Permutation durch eine $\gamma_i$-Operation erreicht werden können. Als einzige Ausnahme von dieser Definition enthält $Q$ zu Beginn nur $p$. Für das vordereste Element der Warteschlange $s$ werden alle $|s|$ möglichen $\gamma_i$-Operationen durchgeführt und die Permutationen $\gamma_i s$ für $0 \le i \le |s|$, die noch nicht besucht wurden, zu $Q$ hinzugefügt. Beim Erreichen einer identischen Permutation wird über eine Vorgängerliste die durchgeführte Operationenfolge rekonstruiert und zurückgegeben. Anders gesagt, es wird eine Breitensuche auf dem Pancake-Graphen von $p$ aus durchgeführt und der kürzeste Pfad zu einer identischen Permutation bestimmt. Da der Pancake-Graph ungewichtet ist, kann Breitensuche zum Finden kürzester Pfade verwendet werden.

Die Vorgängerliste wird durch eine Hashmap für jede Permutationslänge realisiert, die bei $\mu(p)$ den $\mu$-Wert des Vorgängers von $p$ speichert. Um Speicher zu sparen, wird in der Warteschlange außerdem nicht die gesamte Permutation gespeichert, sondern lediglich ihre Länge und ihr $\mu$-Wert, wodurch sie eindeutig bestimmt ist. Wie $\mu(p)$ berechnet und $p$ aus $\mu(p)$ rekonstruiert werden kann, wird später diskutiert. Die Funktion, die eine Permutation $s$ zurückgibt, sodass $\mu(s) = i$ und $|s| = n$, wird im Folgenden einfach mit \textsc{IthPermutation}$(n, i)$ bezeichnet. Der Brute-Force Algorithmus kann als Pseudocode wie folgt zusammengefasst werden.

\begin{algorithm}
    $Q \gets$ Queue containing $(|p|, \mu(p))$ \;
    $pre \gets$ Array of Hashmaps of size $|p|$ \;

    \While{$Q \ne \{\}$}
    {
        $(m, i) \gets $ \textsc{Dequeue}$(Q)$ \;
        $s \gets$ \textsc{IthPermutation}$(m, i)$ \;
        \If{$i = 0$}
        {
            \Return{} \textsc{ReconstructOperations}$(pre, m, i)$ \;
        }

        \For{$j \gets 0$ \KwTo $m - 1$}
        {
            \If{$\mu(\gamma_j s) \notin pre\mathrm{[m - 2]}$}
            {
                $pre[m - 2][\mu(\gamma_j s)] \gets i$ \;
                \textsc{Enqueue}$(Q, (m - 1, \mu(\gamma_j s)))$ \;
            }
        }
    }

    \caption{\textsc{MinOperationsBFS}$(p)$}
\end{algorithm}

\noindent Um die durchgeführten $\gamma_i$-Operationen aus \emph{pre} zu rekonstruieren, wird der aus der Breitensuche entstehende Baum von unten nach oben durchlaufen. Auf dem direkten Vorgänger wird jede mögliche $\gamma_i$-Operation ausprobiert, bis die Richtige gefunden ist.

\begin{algorithm}
    $t \gets$ empty Array \;

    \While{$m < n$}{
        $s \gets$ \textsc{IthPermutation}$(m + 1, pre[m - 1][i])$ \;

        \For{$j \gets 0$ \KwTo $m + 1$}
        {
            \If{$\mu(\gamma_j s) = i$}
            {
                append $j$ to the front of $t$ \;
                \textbf{break} \;
            }
        }

        $i \gets pre[m - 1][i]$ \;
        $m \gets m + 1$ \;
    }
    \Return{t} \;

    \caption{\textsc{ReconstructOperations}$(pre, m, i)$}
\end{algorithm}

\noindent Nun werden die Algorithmen zur Berechnung von $\mu(p)$ und \textsc{IthPermutation} skizziert. Sie werden von Bonet \cite{permutationranking} übernommen, eine formale Beschreibung ist dort zu finden. In dem Artikel wurden mehrere Verfahren zur Abbildung von Permutationen auf Zahlen und umgekehrt vorgestellt. Einige laufen in linearer Zeit, sind aber auf große, vorher erstellte Datenstrukturen angewiesen oder funktionieren nur bis zu einer bestimmten Länge. Daher werden die zwei Verfahren verwendet, die in $\Theta(n \log n)$ Zeit laufen, ohne zusätzliche Datenstrukturen auskommen, und für jede Permutationslänge verwendet werden können.

Zur Berechnung von $\mu(p)$ wird wieder das fakultätsbasierte Zahlensystem zur Hilfe gezogen, indem zunächst die Ziffern von $\mu(p)$ berechnet werden. Dafür wird folgende Eigenschaft verwendet: $\mu(p)_i$ entspricht genau $p_i$ minus der Anzahl links gelegener, kleinerer Elemente in $p$ \cite{permutationranking}. Damit redziert sich das Problem darauf, die Anzahl kleinerer, links gelegener Elemente von $p_i$ zu zählen. Das kann mit einem Segmentbaum in $\Theta(\log n)$ Zeit pro Element gelöst werden, sodass sich insgesamt eine Zeitkomplexität von $\Theta(n \log n)$ ergibt.

Für \textsc{IthPermutation} wird ähnlich vorgegangen. Zunächst werden die Ziffern von $\mu(p)$ im fakultätsbasierten Zahlensystem durch wiederholtes Teilen mit Rest bestimmt. Wie bei der Berechnung der Ziffern einer Zahl im Binärsystem sind die Ziffern die Reste der Folge von Divisionen, nur dass der Divisor nicht konstant ist, sondern zuerst 1, dann 2, 3 und so weiter. Die Indizes von $p$ werden anschließend aufsteigend bearbeitet, man nehme also im Folgenden an, dass $p_i$ gerade bestimmt werden soll und $p_j$ für $j < i$ bereits bekannt ist. Mit der Tatsache, dass $\mu(p)_i$ genau $p_i$ minus der Anzahl kleinerer, links gelegener Elemente ist, reduziert sich das Problem darauf, zu bestimmen, welchen Wert $p_i$ annehmen muss, sodass es genau $\mu(p)_i$ kleinere Elemente links davon gibt. Auch das lässt sich mit einem Segmentbaum in $\Theta(\log n)$ Zeit pro Element lösen. Für ihn gilt folgende Invariante: Ist ein Element $y$ noch nicht aufgetreten, steht eine 1 bei Index $y-1$, andernfalls eine 0. Zur Bestimmung von $p_i$ wird der Segmentbaum von oben nach unten heruntergelaufen und die Schritte so gewählt, dass die Summe links gelegener Elemente genau $\mu(p)_i$ ist. Aber dadurch landet man genau bei dem $p_i$-ten Element des Segmentbaums, denn links liegen $\mu(p)_i$ Einsen plus die Anzahl bereits aufgetretener, kleinerer Elemente, die im Segmentbaum bereits auf 0 gesetzt wurden. Nun wird auch $p_i$ im Segmentbaum auf 0 gesetzt und so die Invariante erhalten. Insgesamt erhält man auch hier eine Zeitkomplexität von $\Theta(n \log n)$.
\bigskip

\noindent \emph{Eine Unterschranke für $A(p)$.} Mit einer Unterschranke für die Anzahl an benötigten $\gamma_i$-Operationen wird es möglich sein, während der Suche manche Permutationen außer Acht zu lassen, da sie nicht zu einem besseren Ergebnis führen können. Wir betrachten die Anzahl an monoton steigenden oder fallenden Teilstrings in einer Permutation. Ein monoton steigender Teilstring $T$ von Länge $k$ einer Permutation $p$ ist eine Menge an Indizes $\{i, i + 1, \dots, i + k - 1\}$, so, dass $p_{j+1} > p_j$ für $i \le j \le i+ k - 2$ und $T$ bezüglich dieser Eigenschaft maximale Länge hat. Ein monton fallender Teilstring ist ähnlich definiert, nur gilt $p_{j + 1} < p_j$ für $i \le j \le i + k - 2$. Ein monotoner Teilstring ist ein monoton steigender oder fallender Teilstring. Nach dieser Definition ist ein Element von $p$, dessen Nachbarn beide größer oder kleiner sind, Teil von 2 monotonen Teilstrings. Die identische Permutation besteht offensichtlich nur aus einem monoton steigenden Teilstring. Mithilfe von folgendem Lemma kann dann einfach eine untere Schranke für $A(p)$ bestimmt werden.

\begin{lemma}
    Pro $\gamma_i$-Operation kann die Anzahl monotoner Teilstrings einer Permutation $p$ maximal um 3 reduziert werden.
\end{lemma}

\begin{proof}
    Die Anzahl monotoner Teilstrings in $p$ wird im Folgenden $x$ genannt. Die Veränderung von $x$ durch eine $\gamma_i$-Operation wird $\Delta x$ genannt. Zunächst bemerkt man, dass sich die Zahl monotoner Teilstrings nur durch Hinzufügen bzw. Entfernen von Teilstrings, die $p_0$ oder $p_i$ enthalten, verändern kann. Wir unterscheiden zwei Fälle: Entweder ist $p_i$ Teil von zwei oder von einem monotonen Teilstring.

    Im ersten Fall werden wieder einige Fälle unterschieden. Zunächst wird nur der Beitrag zu $\Delta x$ von Teilstrings mit $p_i$ betrachtet.

    \begin{enumerate}
        \item $p_{i + 1}$ ist Teil von zwei monotonen Teilstrings. Das bedeutet, $p_i, p_{i + 1}$ ist ein monotoner Teilstring von Länge 2.
              \begin{enumerate}
                  \item $p_{i - 1}$ ist Teil von zwei monotonen Teilstrings $\Longrightarrow \Delta x = - 2$.
                  \item $p_{i - 1}$ ist Teil von einem monotonen Teilstring $\Longrightarrow \Delta x = - 1$.
              \end{enumerate}
        \item $p_{i + 1}$ ist Teil von einem montonen Teilstring.
              \begin{enumerate}
                  \item $p_{i - 1}$ ist Teil von zwei monotonen Teilstrings $\Longrightarrow \Delta x = - 1$.
                  \item $p_{i - 1}$ ist Teil von einem monotonen Teilstring $\Longrightarrow \Delta x = 0$.
              \end{enumerate}
    \end{enumerate}

    \noindent   Für den Beitrag von $p_0$ werden folgende Fälle unterschieden.

    \begin{enumerate}
        \item $p_0 < p_{i + 1}$
              \begin{enumerate}
                  \item $p_0 < p_1$
                        \begin{enumerate}
                            \item $p_{i + 1} < p_{i + 2} \Longrightarrow \Delta x = 0$
                            \item $p_{i + 1} > p_{i + 2} \Longrightarrow \Delta x = 1$
                        \end{enumerate}
                  \item $p_0 > p_1$
                        \begin{enumerate}
                            \item $p_{i + 1} < p_{i + 2} \Longrightarrow \Delta x = -1$
                            \item $p_{i + 1} > p_{i + 2} \Longrightarrow \Delta x = 0$
                        \end{enumerate}
              \end{enumerate}
        \item $p_0 > p_{i + 1}$ Der Fall ist symmetrisch zu $p_0 < p_{i + 1}$.
    \end{enumerate}

    \noindent Man sieht, dass $\Delta x$ insgesamt nicht kleiner als $-3$ sein kann. Für den Fall, dass $p_i$ Teil von einem monotonen Teilstring ist, muss nur der Beitrag von $p_i$ neu betrachtet werden. Da aber bereits festgestellt wurde, dass nur Teilstrings, die $p_0$ oder $p_i$ enthalten, verschwinden können und $p_i$ nur Teil von einem monotonen Teilstring ist, gilt $\Delta x \ge -1$, sodass in allen Fällen $\Delta x \ge - 3$ ist.

    Bisher wurde implizit angenommen, dass $1 \le i \le n - 3$ gilt, da $p_{i-1}, p_{i + 1}$ und $p_{i + 2}$ in Betracht gezogen wurden. Wenn $i = 1$ oder $i = n - 1$, gilt offensichtlich $\Delta x \in \{0, -1\}$. Wenn $i = n - 2$, gilt $\Delta x \ge -2$, was mit der gleichen Fallunterscheidung wie oben überprüft werden kann.
\end{proof}

Damit kann nun Folgendes gezeigt werden.

\begin{theorem}
    Sei $x$ die Anzahl monotoner Teilstrings einer Permutation $p$. Dann gilt
    $$ A(p) \ge \bigg{\lfloor} \frac {x + 1} 3 \bigg{\rfloor} $$.
\end{theorem}

\begin{proof}
    Die identische Permutation besitzt genau einen monotonen Teilstring, d. h. durch die $\gamma_i$-Operationen müssen insgesamt $x - 1$ monotone Teilstrings entfernt werden. Wenn $x - 1$ durch 3 teilbar ist, sind dafür nach Lemma 3 mindestens
    \begin{align*}
        \frac {x - 1} 3 = \frac {x - 1} 3 + \bigg{\lfloor} \frac 2 3 \bigg{\rfloor}
        = \bigg{\lfloor} \frac {x - 1} 3 + \frac 2 3 \bigg{\rfloor} =
        \bigg{\lfloor} \frac {x + 1} 3 \bigg{\rfloor}
    \end{align*}
    Operationen nötig. Wenn $x - 1 \equiv 1 \bmod 3$, ist neben den mindestens $(x - 2)/3$ Operationen mit $\Delta x = -3$ noch mindestens eine weitere Operation nötig. Insgesamt ergibt sich eine Unterschranke von
    \begin{align*}
        \frac {x - 2} 3 + 1 = \frac {x - 2} 3 + \frac 3 3 = \frac {x + 1} 3
    \end{align*}
    Für $x - 1 \equiv 2 \bmod 3$ sind mindestens $(x - 3) / 3$ Operationen mit $\Delta x = -3$ und eine weitere erforderlich.
    \begin{align*}
        \frac {x - 3} 3 + 1 = \frac x 3 = \bigg{\lfloor} \frac {x + 1} 3 \bigg{\rfloor} \quad (\text{da } x \equiv 0 \bmod 3)
    \end{align*}
\end{proof}

Die untere Schranke kann mit folgendem Algorithmus berechnet werden. Für jedes Element von $p$ wird überprüft, ob bei ihm ein neuer monotoner Teilstring beginnt und der Zähler entsprechend erhöht. Die Laufzeit beträgt wegen der for-Schleife $\Theta(n)$.

\begin{algorithm}
    \If{$n = 1$}
    {
        \Return{$0$} \;
    }

    $x \gets 1$ \;
    $incr \gets p_1 > p_0$ \;

    \For{$i \gets 2$ \KwTo $n - 1$}
    {
        \If{$(incr \land (p_{i-1} > p_i)) \lor (\neg incr \land (p_{i-1} < p_i))$}
        {
            $incr \gets \neg incr$ \;
            $x \gets x + 1$ \;
        }
    }

    \Return{$\lfloor (x + 1)/ 3 \rfloor$} \;

    \caption{\textsc{LowerBound}(p)}
\end{algorithm}

\noindent \emph{Ein A*-basiertes Verfahren.} Mit der unteren Schranke wird das Brute-Force Verfahren nun in zwei Aspekten verbessert.

\begin{enumerate}
    \item Anstatt der Warteschlange wird eine Prioritätswarteschlange verwendet, in der die Knoten aufsteigend nach unterer Schranke geordnet sind. Damit werden vielversprechende Pfade früher besucht.
    \item Die kürzeste bisher gefundene Distanz zu einer identischen Permutation wird ständig gespeichert, um das Besuchen unnötiger Knoten zu vermeiden. Ist die untere Schranke eines Knotens größer oder gleich der aktuell kürzesten Distanz, kann dieser nicht zu einem besseren Ergebnis führen.
\end{enumerate}

Aus graphentheoretischer Sicht entspricht das einer Ausführung des A*-Algorithmus auf dem Pancake-Graphen. Der Pseudocode sieht wie folgt aus.

\begin{algorithm}

    $Q \gets$ Priority Queue containing $(\mu(p), n, \textsc{LowerBound}(p))$ \;
    $pre \gets$ Array of Hashmaps of size $n$ \;
    $ubound \gets n$ \;
    $n'$ \;

    \While{$Q \ne \{\}$}
    {
        $(i, m, b) \gets$ \textsc{Dequeue}$(Q)$ \;
        \If{$b \ge ubound$}
        {
            \textbf{break} \;
        }

        \If{$i = 0$}
        {
            \If{$n - m < ubound$}
            {
                $n' \gets m$ \;
                $ubound \gets n - m$ \;
            }
            \textbf{continue} \;
        }

        $s \gets$ \textsc{IthPermutation}$(m, i)$ \;

        \For{$j \gets 0$ \KwTo $m - 1$}
        {
            \If{$\mu(\gamma_j s) \notin pre[m - 2] \land n - m + \text{\textsc{LowerBound}}(\gamma_j s) + 1 < ubound$}
            {
                $pre[m - 2][\mu(\gamma_j s)] \gets i$ \;
                \textsc{Enqueue}$(Q, (\mu(\gamma_j s), m - 1, n - m + \textsc{LowerBound}(\gamma_j s) + 1))$ \;
            }
        }
    }

    \Return{\textsc{ReconstructOperations}$(pre, n', 0)$} \;

    \caption{\textsc{MinOperationsA*}(p)}
\end{algorithm}

Die Knoten werden in $Q$ als 3-Tupels mit Index, Länge und unterer Schranke gespeichert. Beim Einfügen eines neuen Knotens in $Q$ wird dessen untere Schranke auf die Anzahl bisher ausgeführter $\gamma_i$-Operationen plus der von \textsc{LowerBound} geschätzten Zahl plus 1 für die gerade durchgeführte Operation gesetzt. $n'$ speichert die Länge der aktuell besten gefunden identischen Permutation.
\bigskip

\noindent \emph{Branch and Bound.} Zum Vergleich mit dem A*-Verfahren wird noch ein Branch and Bound-Algorithmus vorgestellt. Er nutzt ebensfalls die hergeleitete untere Schranke für $A(p)$. Es wird keine Prioritätswarteschlange über alle Äste der Suche verwaltet, sondern lediglich über die direkten Nachfolger eines Knotens. Die Prioritätswarteschlange $Q$ enthält Paare bestehend aus der unteren Schranke des Nachfolgers und dem $i$ der $\gamma_i$-Operation, die zu ihm führt. Die Nachfolger sind in $Q$ aufsteigend nach unterer Schranke geordnet und werden in Reihenfolge abgearbeitet. Während A* auf Breitensuche basiert ist, arbeitet dieses Verfahren eher wie Tiefensuche: Bevor der nächste Nachfolgerknoten abgearbeitet wird, wird der aktuelle vollständig abgeschlossen. Das heißt, es wird entweder eine identische Permutation erreicht oder festgestellt, dass keine bessere Lösung als die akutelle Oberschranke existiert. Wenn in der Prioritätswarteschlange nur noch Knoten mit einer größeren Unterschranke als der aktuellen Oberschranke vorhanden sind, wird abgebrochen und die aktuell beste Lösung zurückgegeben. Die Rückgabe besteht aus einem Paar: Ein Array von Wendeoperationen und ein Wahrheitswert, der angibt, ob eine bessere Lösung gefunden wurde. Da der Algorithmus, wie für Tiefensuche üblich, rekursiv arbeitet, wird die Datenstruktur $pre$ zum Speichern des Vorgängers nicht benötigt, das geschieht implizit durch den Stapel rekursiver Aufrufe. Um dennoch zu wissen, welche Knoten bereits besucht wurden, wird ein Array von Hashsets $vis$ angelegt, in dem für jede Permutationslänge die Indizes besuchter Permutationen enthalten sind. Der Pseudocode sieht wie folgt aus.

\begin{algorithm}
    \If{$\mu(p) = 0$}
    {
        \Return{\emph{(empty array, \textbf{true})}} \;
    }
    \If{$\mu(p) \in vis[n - 1]$}
    {
        \Return{\emph{(empty array, \textbf{false})}} \;
    }

    $Q \gets \{(\textsc{LowerBound}(\gamma_i p), i) : 0 \le i \le n - 1\}$ \;
    $res \gets$ empty array \;
    $better \gets$ \textbf{false} \;

    \While{$Q \ne \{\}$}
    {
        $(lbound, i) \gets$ \textsc{Dequeue}$(Q)$ \;
        \If{$lbound \ge ubound$}
        {
            \textbf{break} \;
        }

        (\emph{op}, \emph{found}) $\gets$ \textsc{MinOperationsBnB}$(\gamma_i p, vis, ubound - 1)$ \;
        \If{$\text{found} \land |op| + 1 < ubound$}
        {
            $ubound \gets |op| + 1$ \;
            $res \gets op$ with $i$ appended at front \;
            $better \gets$ \textbf{true} \;
        }
    }

    $vis[n - 1] \gets vis[n - 1] \cup \mu(p)$ \;
    \Return{\emph{(}res, better\emph{)}} \;

    \caption{\textsc{MinOperationsBnB}$(p, vis, ubound)$}
\end{algorithm}

\noindent Beim rekursiven Aufruf muss \emph{ubound} um 1 verringert werden, da durch die $\gamma_i$-Operation auf $p$ nun eine $\gamma_i$-Operation weniger zur Verfügung steht. In \emph{better} wird gespeichert, ob einer der Nachfolgerknoten zu einem neuen besten Ergebnis führen kann.

\subsection{Berechnung der PWUE-Zahl}

Für diese Teilaufgabe wird Dynamische Programmierung verwendet. Man nehme an, ein Array $y$ enthält bei Index $i$ $A(p)$, für jedes $0 \le i \le (k - 1)! - 1$, wobei $|p| = k - 1$ und $\mu(p) = i$. Den Wert von $A(q)$ einer Permutation $q$ der Länge $k$ zu berechnen, ist mithilfe von $y$ einfach.
\begin{align*}
    A(q) = \min_{0 \le i \le k - 1}  y[\mu(\gamma_i q)] + 1
\end{align*}
Die einzige Ausnahme ist $q = I^k$, hier gilt natürlich $A(q) = 0$. Hat man $A(q)$ für jede Permutation der Länge $k$ berechnet, schreibt man diese wieder in $y$ und kann mit $k + 1$ fortfahren. Dies wird solange fortgeführt, bis man $n$ erreicht hat. Während $A(p)$ für jede Permutation der Länge $n$ berechnet wird, kann $P(n)$ als laufendes Maximum aktualisiert werden, und der Index einer Permutation mit $A(p) = P(n)$ gespeichert werden. Zu Beginn enthält $y$ ausschließlich eine 0 bei Index 0, da für $I^1$ 0 Operationen benötigt werden. Bevor die Werte von $A(p)$ der Permutationen von Länge $k$ in $y$ geschrieben werden können, müssen alle berechnet sein, daher werden sie in einem weiteren Array $z$ zwischengespeichert. Um die Effizienz des Algorithmus zu erhöhen, kann hier die Symmetrie des Pancake-Graphen ausgenutzt werden: Nach obiger Formel muss für eine Permutation $k$ Mal $\gamma_i p$ und anschließend $\mu(\gamma_i p)$ berechnet werden. Da $\mu(\gamma_i p^*) = (k - 1)! - \mu(\gamma_i p) - 1$, können diese Berechnungen auf die Hälfte reduziert werden. Des weiteren muss $A(p)$ für Permutationen der Länge $n$ nicht mehr in $z$ gespeichert werden, sondern nur das laufende Maximum $a_{\max}$ aktualisiert werden. Es ergibt sich folgender Algorithms. $u$ und $v$ enthalten in der äußeren for-Schleife immer $k!$ bzw. $(k - 1)!$.

\begin{algorithm}
    $y \gets \{0\}, z \gets$ empty array \;
    $u \gets 1, v \gets 1$ \;

    \For{$k \gets 2$ \KwTo $n - 1$}
    {
        $u \gets u \cdot k$ \;

        \For{$i \gets 0$ \KwTo $u / 2$}
        {
            $p \gets$ \textsc{IthPermutation}$(k, i)$ \;

            \For{$j \gets 0$ \KwTo $k$} {
                $l \gets \mu(\gamma_j p)$ \;
                $z[i] \gets \min(z[i], y[l] + 1)$ \;
                $z[u - i - 1] \gets \min(z[u - i - 1], y[v - l - 1] + 1)$ \;
            }
        }

        $z[0] \gets 0$ \;
        swap($y, z$) \;
        $v \gets v \cdot k$ \;
    }
    $u \gets u \cdot n$ \;
    $a_{\max} \gets 0$, \emph{example} $\gets 0$ \;
    \For {$i \gets 0$ \KwTo $u$}
    {
        $a \gets n$ \;
        $p \gets$ \textsc{IthPermutation}$(n, i)$ \;
        \For{$j \gets 0$ \KwTo $n$}
        {
            $a \gets \min(a, y[\mu(\gamma_j p)])$ \;
        }
        \If{$a > a_{\max}$}
        {
            $a_{\max} \gets a$ \;
            \emph{example} $\gets i$ \;
        }
    }

    \Return{\emph{(}$a_{\max}, example$\emph{)}} \;

    \caption{\textsc{Pwue}$(n)$}
\end{algorithm}

\emph{Anmerkung.} Es wurden auch andere Verfahren in Betracht gezogen, die nicht einfach $A(p)$ für jede Permutation berechnen. Diese stellten sich jedoch als praktisch wenig brauchbar heraus. Hier soll kurz eines davon erläutert werden. Wir nennen
\begin{align*}
    \Gamma(p) = \{\gamma_i p : 0 \le i \le |p|\}
\end{align*}
die Menge aller von $p$ durch eine $\gamma_i$-Operation erreichbaren Permutationen der Länge $|p| - 1$. Daneben wird $S_m^n$ als die Menge aller Permutationen von Länge $n$ mit $A(p) = m$ definiert. Eine Permutation $p$ gehört zu den schwierigsten Permutationen seiner Länge, wenn $\Gamma(p) \subseteq S_{n - 1}^{P(n-1)}$. Wenn keine solche Permutation der Länge $n$ existiert, gehört $p$ zu den schwierigsten Permutationen, wenn $\Gamma(p) \subseteq S_{n - 1}^{P(n-1)} \cup S_{n - 1}^{P(n-1) - 1}$. Das heißt, von $p$ aus sind nur schwierigste (oder zweitschwierigste) Permutationen der Länge $n - 1$ erreichbar. Basierend auf der Idee, dass zur Berechnung von $P(n)$ eigentlich nur die schwierigsten Permutationen der Länge $n$ berechnet werden müssen, kann man sich wieder einen DP-Algorithmus überlegen. Zur Berechnung der schwierigsten Permutationen der Länge $n$ benötigt man $S_{n - 1}^{P(n)}$, aber möglicherweise auch $S_{n - 1}^{P(n)-1}$. Zu deren Berechnung benötigt man wiederum $S_{n - 2}^{P(n - 2)}$, aber möglicherweise auch $S_{n - 2}^{P(n - 2) - 1}$ und $S_{n - 2}^{P(n - 2) - 2}$. Führt man das fort, sind irgendwann alle Permutationen einer bestimmten Länge nötig. Wir nennen diese Länge $m$. Nun wird die Umkehrung von $\gamma_i$ definiert: $\gamma_{i, r}^{-1} p$ ist eine Permutation der Länge $n + 1$, sodass $\gamma_i q = p$ und $q_i = r$. Der Algorithmus sieht dann wie folgt aus: Man startet mit allen Permutationen der Länge $m$, und verwendet $\gamma_{j, r}^{-1}$ für jedes $0 \le, j, r \le m + 1$ um $S_{m + 1}^{1}, S_{m + 1}^2, \dots, S_{m + 1}^{P(m+1)}$ zu berechnen. Hier müssen noch fast alle Permutationen der Länge $m + 1$, außer $I^{m + 1}$ gespeichert werden. Führt man das Verfahren aber fort und wendet $\gamma_{i, r}^{-1}$ auf jede Permutation in einer der eben berechneten Mengen an, erhält man $S_{m + 2}^2, S_{m + 2}^3, \dots, S_{m + 2}^{P(m +2)}$. Mit jeder Iteration müssen verhältnismäßig weniger Permutationen gespeichert werden. Nach $n - m$ Iterationen wird so $S_n^{P(n)}$ berechnet. Praktisch ergeben sich jedoch folgende Probleme.

\begin{itemize}
    \item Wenn nicht mehr jede Permutation abgespeichert wird und kein Array der Länge $n!$ angelegt werden soll, muss zu jedem $A(p)$ der Index von $p$ gespeichert werden. Während $A(p)$ problemlos in 8 Bits passt, sind für $\mu(p)$ 64 Bits nötig, mit $|p| \ge 12$. Der Speicherverbrauch wird so 8 Mal größer. Es werden natürlich auch weniger Permutationen gespeichert, aber die Reduktion ist nicht so stark wie der Anstieg des Speicherverbrauchs.
    \item Das Ausnutzen der Symmetrie des Pancake-Graphen wird schwierig. Bevor $A(p^*)$ für den symmetrischen Partner $p^*$ abgespeichert werden kann, muss überprüft werden, ob dieser überhaupt noch in einer der betrachteten Mengen von Permutationen liegt. Auch wenn zum Abspeichern der Permutationen ein balancierter Binärbaum, ein Hashset oder einfach ein nach Index sortiertes Array verwendet wird, ist das in jedem Fall aufwändig.
    \item Parallelisierung wird ineffizient. Eine parallele Ausführung der $\gamma_{i, r}^{-1}$-Operationen auf Permutationen der Länge $k - 1$ führt zu gleichzeitigen Veränderungen der Datenstrukturen, die $S_k^j, S_{k}^{j + 1}, \dots, S_{k}^{P(k)}$ verwalten. Dagegen kann der Algorithms \textsc{Pwue} einfach parallelisiert werden.
\end{itemize}

\section{Laufzeitanalyse}

\subsection{Teilaufgabe a)}

Zunächst wird die Laufzeit von \textsc{ReconstructOperations} abgeschätzt. In \textsc{ReconstructOperations} wird die while-Schleife maximal $n - m$ Mal durchgeführt, da $m$ in jeder Iteration um 1 erhöht wird. Die for-Schleife durchläuft jeweils $m + 2$ Iterationen und in jeder wird einmal $\mu(s)$ berechnet, wobei $|s| = m+1$ gilt. Im schlechtesten Fall, wenn $m = 1$, kann die Laufzeit wie folgt beschränkt werden. ($c$ ist eine positive Konstante.)
\begin{align*}
    \sum_{m = 1}^n \sum_{j = 0}^{m+1} \Theta(m \log m)
     & = \sum_{m = 1}^n \sum_{j = 0}^{m+1} cm \log m \\
     & = c \sum_{m = 1}^n (m + 2)m \log m            \\
     & = c \sum_{m = 1}^n m^2 \log m + 2 m \log m    \\
     & \le c \sum_{m = 1}^n n^2 \log n  + 2 n \log n \\
     & = cn^3 \log n + 2cn^2 \log n                  \\
\end{align*}
Eine obere Schranke ist für die Worst Case-Laufzeit ist folglich $O(n^3 \log n)$. Für eine untere Schranke im Worst Case gilt
\begin{align*}
    \sum_{m = 1}^n \sum_{j = 0}^{m+1} cm \log m
     & = c \sum_{m = 1}^n m^2 \log m                                                                                                          \\
     & \ge c \sum_{m = \lfloor n / 2 \rfloor}^{n} \bigg{\lfloor} \frac {n} {2} \bigg{\rfloor} ^2 \log \bigg{\lfloor} \frac n 2 \bigg{\rfloor} \\
     & = c \bigg{\lceil} \frac n 2 \bigg{\rceil} \bigg{\lfloor} \frac n 2 \bigg{\rfloor} ^2 (\log n - \Theta (1))                             \\
     & \ge c \frac {n(n - 1)^2}  8 (\log n - \Theta (1))                                                                                      \\
     & = c \frac {n^3 - 2n^2 + n} 8 (\log n - \Theta (1))
\end{align*}
Nach unten kann die Laufzeit also mit $\Omega(n^3 \log n)$ beschränkt werden. Da obere und untere Schranke übereinstimmen beträgt die Worst-Case Zeitkomplexität von \textsc{ReconstructOperations} $\Theta(n^3 \log n)$. Im Best Case gilt $m = n$ und die Zeitkomplexität beträgt $\Theta(1)$, da die while-Schleife nie ausgeführt wird.

Um die Laufzeit der drei Algorithmen für Teilaufgabe a) begrenzen zu können, wird eine obere Schranke für die Suchtiefe benötigt. Die beste Schranke wäre natürlich $P(n)$, die Funktion kann aber nicht als geschlossener Ausdruck geschrieben werden. Daher wird folgende Oberschranke für $A(p)$ verwendet.

\begin{lemma}
    $A(p) \le \Big{\lceil} \frac {2n} 3 \Big{\rceil}$
\end{lemma}

\begin{proof}
    Wir betrachten folgenden Algorithmus zum Sortieren von $p$:
    \begin{enumerate}
        \item Sei $i$ der Index des größten Elements von $p$, das nicht in einem sortierten Suffix liegt. Führe die Operation $\gamma_{i+1}$ aus. Damit wird das größte, noch nicht einsortierte Element nach vorne gebracht.
        \item Führe die Operation $\gamma_{j-1}$ aus, wobei $j$ der kleinste Index eines Elements im sortierten Suffix ist.
    \end{enumerate}
    Da immer das größte Element, das nicht im sortierten Suffix liegt, gewählt wird, wird das sortierte Suffix mit jeder Ausführung dieser zwei Schritte um ein Element vergrößtert. Da gleichzeitig zwei Elemente aus $p$ entfernt werden, besteht $p$ spätestens nach $\lceil 2n / 3 \rceil$ Schritten nur noch aus dem sortierten Suffix.
\end{proof}

Dass die Oberschranke nicht schlecht ist, zeigt das Beispiel $n = 3$. Denn $P(3) = 2$, und die Oberschranke für 3 wäre ebensfalls 2.

Die Gesamtlaufzeit von \textsc{MinOperationsBFS} wird durch die Anzahl besuchter Knoten auf jeder Ebene und die Zeit pro Knoten abgeschätzt. Von Länge $n$ wird genau eine Permutation, $p$, besucht. Davon ausgehend gibt es $n$ Möglichkeiten für eine $\gamma_i$-Operation, also werden maximal $n$ Permutationen der Länge $n - 1$ besucht. Von diesen werden durch $\gamma_i$-Operationen maximal $n(n-1)$ Permutationen der Länge $n - 2$ erreicht. Diese Argumentation lässt sich rekursiv fortführen, es werden also maximal $n! / k!$ Knoten der Länge $k$ besucht. Für kleine $k$ ist $n! / k!$ jedoch größer als $k!$, da es aber nur $k!$ Permutationen der Länge $k$ gibt und kein Knoten doppelt besucht wird, kann die Anzahl besuchter Knoten durch $\min(n! / k!, k!)$ beschränkt werden. Mit Lemma 4 kann $k$ nach unten durch $\lfloor n/3 \rfloor$ begrenzt werden. Summiert man für alle $k$ von $\lfloor n/3 \rfloor$ bis $n$ auf, ergibt sich folgende Oberschranke für die Anzahl besuchter Knoten. Zur Auswertung der Fakultät wird die Stirlingformel verwendet.
\begin{align*}
    \sum_{k = \lfloor n/3 \rfloor}^n \min \bigg ( \frac {n!}{k!}, k! \bigg )
     & \le \sum_{k = \lfloor n/3 \rfloor}^n  \frac {n!} {(n/3)!}
    \\ & \le n \cdot \frac {n!} {(n/3)!}
    \\ & \approx n \cdot
    \frac {\sqrt{2 \pi n} \cdot (n/e)^n} {\sqrt{2 \pi n/3} \cdot (n/3e)^n}
    \\ & = n \cdot
    \frac {n^n / e^n} {\sqrt{1/3} \cdot n^n / (3e)^n}
    \\ & = \sqrt 3 \cdot 3^n \cdot n
\end{align*}

Die Anzahl besuchter Knoten ist also $O(3^n \cdot n)$. Beim Einsetzen des kleinstmöglichen $k = \lfloor n/3 \rfloor$ in der ersten Zeile wurde die Abrundungsfunktion der Einfachheit halber weggelassen, am asymptotischen Verhalten ändert das jedoch nichts.

Für einen Knoten der Länge $k$ ergeben sich zweimal $\Theta(k \log k)$ Schritte: Erstens durch den Aufruf von \textsc{IthPermutation}, und zweitens durch die Berechnung von $\mu(p)$, als die Permutation von ihrem Vorgänger zur Warteschlange hinzugefügt wurde. $\gamma_i$ kann einfach in $\Theta(k)$ Schritten berechnet werden und ist damit nicht relevant. Folglich ergeben sich $\Theta(k \log k)$ Schritte für eine Permutation der Länge $k$. Mit der Oberschranke für die Anzahl besuchter Knoten l��sst sich die Worst Case-Laufzeit von \textsc{MinOperationsBFS} durch
\begin{align*}
    O(3^n \cdot n^2 \log n)
\end{align*}
beschränken. Da die Laufzeit exponentiell steigt, ist der Beitrag von $\Theta(n^3 \log n)$ von \textsc{ReconstructOperations} nicht relevant.

Für \textsc{MinOperationsA*} bleibt die Laufzeit grundsätzlich gleich, da im schlechtesten Fall dennoch alle Knoten besucht werden. Für einen Knoten kommt lediglich ein logarithmischer Faktor vom Einfügen in die Prioritätswarteschlange hinzu. Die Größe der Prioritätswarteschlange kann mit der Anzahl besuchter Knoten, $O(3^n \cdot n)$ begrenzt werden. Folglich ist die Worst-Case Zeitkomplexität von \textsc{MinOperationsA*}
\begin{align*}
    O(3^n \cdot n^2 \log n) \cdot \log O(3^n \cdot n)
     & = O(3^n \cdot n^2 \log n) \cdot O(\log (3^n \cdot n)) \\
     & = O(3^n \cdot n^2 \log n) \cdot O(n \log n)           \\
     & = O(3^n \cdot n^3 \log^2 n)
\end{align*}

Die Worst Case-Laufzeit von \textsc{MinOperationsBnB} pro Knoten beträgt $O(n^2)$, da für jeden der maximal $n$ Nachfolgerknoten \textsc{LowerBound} ausgeführt wird. Ebenfalls $O(n)$ Zeit pro Nachfolgerknoten benötigt das mögliche Kopieren von \emph{op} zu \emph{res}. Der Beitrag der Prioritätswarteschlange ist nur $O(n \log n)$, da ein Knoten maximal $n$ Nachfolger hat, und $\mu(p)$ benötigt $\Theta(n \log n)$ Zeit. Im Worst Case beträgt die Laufzeit von \textsc{MinOperationsBnB} also
\begin{align*}
    O(3^n \cdot n^3)
\end{align*}

Im Best Case, wenn die Eingabe eine identische Permutation ist, beträgt die Laufzeit aller drei Verfahren $\Theta(n \log n)$, da einmal $\mu(p)$ berechnet bzw. \textsc{IthPermutation} ausgeführt wird.

\subsection{Teilaufgabe b)}

\section{Implementierung}

\subsection{Hilfsfunktionen}

\subsection{Teilaufgabe a)}

\subsection{Teilaufgabe b)}

\section{Beispiele}

\subsection{Beispiele der BWINF-Website}

\subsection{Eigene Beispiele}

\subsection{Werte von $P(n)$}

\section{Quellcode}

\subsection{util.cpp}

\subsection{aufgabe3\_a.cpp}

\subsection{aufgabe3\_b.cpp}

\begin{thebibliography}{5}
    \bibitem{permutationranking}
    Bonet, B. (2008).
    Efficient Algorithms to Rank and Unrank Permutations in Lexicographic Order. \\
    https://www.aaai.org/Papers/Workshops/2008/WS-08-10/WS08-10-004.pdf

    \bibitem{burntpancakes}
    Cohen, D. S., Blum, M. (1993).
    On the problem of sorting burnt pancakes. \\
    https://www.sciencedirect.com/science/article/pii/0166218X94000093

    \bibitem{discretemath}
    Johnsonbaugh, R. (2017).
    Discrete Mathematics (8. Auflage).
    Pearson Verlag.

    \bibitem{factorial}
    Wikipedia (2022).
    Factorial number system. \\
    https://en.wikipedia.org/wiki/Factorial\_number\_system

    \bibitem{lexicographic}
    Wikipedia (2022).
    Lexicographic order. \\
    https://en.wikipedia.org/wiki/Lexicographic\_order
\end{thebibliography}

\end{document}