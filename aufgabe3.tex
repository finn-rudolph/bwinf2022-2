\documentclass[a4paper, 11pt, ngerman]{article}
\usepackage{tikz-network}
\usepackage[left=3cm, right = 3cm, top=3cm, bottom=3cm, head=13.6pt]{geometry}
\usepackage{babel}
\usepackage[T1]{fontenc}
\usepackage{inputenc}
\usepackage[noend,nosemicolon,algoruled,noline]{algorithm2e}
\usepackage{amsmath}
\usepackage{amsthm}
\usepackage[nottoc,notlot,notlof]{tocbibind}
\usepackage{graphicx}
\usepackage{float}
\usepackage{enumitem}
\usepackage{listings}
\usepackage{color}
\usepackage{booktabs}

\newcommand{\Aufgabe}{Aufgabe 3: Pancake Sort}
\newcommand{\TeilnahmeId}{67571}
\newcommand{\Name}{Finn Rudolph}

\usepackage{scrlayer-scrpage, lastpage}
\setkomafont{pageheadfoot}{\textrm}
\rohead{Teilnahme-ID: \TeilnahmeId}
\lohead{\Aufgabe}
\cfoot*{\thepage{}}

\title{\LARGE \textbf{Aufgabe 3: Pancake Sort}}
\author{\large Finn Rudolph \\ \\ \large Teilnahme-ID: 67571}
\date{\large 28. Dezember 2022}

\setlist[enumerate]{label*={\arabic*.}}

\definecolor{keyword}{rgb}{0.2, 0.0, 0.7}
\definecolor{comment}{rgb}{0.5, 0.5, 0.5}
\definecolor{number}{rgb}{0.5, 0.5, 0.5}
\definecolor{string}{rgb}{0.3, 0.65, 0.0}

\lstset
{
    basicstyle=\scriptsize\ttfamily,
    keywordstyle=\color{keyword},
    commentstyle=\color{comment},
    numberstyle=\tiny\color{number},
    stringstyle=\color{string},
    numbers=left,
    showspaces=false,
    showstringspaces=false
}

\begin{document}

\begin{titlepage}
    \maketitle
    \tableofcontents
    \thispagestyle{empty}
\end{titlepage}

\newtheorem{theorem}{Satz}
\newtheorem{lemma}{Lemma}
\theoremstyle{definition}
\newtheorem{definition}{Definition}

\section{Lösungsidee}

Pancake Sort ist ein bekannter Sortieralgorithmus, in seiner ursprünglichen Form wird der oberste Pfannkuchen allerdings nicht aufgegessen, sondern allein ein Präfix der zu sortierenden Folge umgekehrt. Pancake Sort wird daher auch als \emph{Sorting by Prefix Reversals} bezeichnet. Der Algorithmus wird zwar nicht direkt zum Sortieren verwendet, der mit ihm verbundene Pancake Graph dient jedoch beispielsweise als Grundlage für Netzwerke für parallele Computersysteme.

Ein Stapel von $n$ Pfannkuchen wird als Permutation
$$
    p = p_0, p_1, p_2, \dots, p_{n - 1}
$$
definiert, wobei $0 \le p_i \le n-1$ und $p_i \ne p_j$, für $0 \le i, j \le n-1$ und $i \ne j$. $p_0$ ist der oberste Pfannkuchen, $p_{n - 1}$ der unterste. Die Elemente von $p$ mit 0 beginnend zu indexieren und die $p_i$ bei 0 beginnen zu lassen, wird später einige Vereinfachungen bringen. Um eine Wende-und-Ess-Operation kompakt auszudrücken, wird der Wende-und-Ess-Operator $\gamma_i$ eingeführt.

\begin{definition}
    Sei $p$ eine Permutation von Länge $n$. Der Wende-und-Ess-Operator $\gamma_i$ ist für $p$ wie folgt definiert.
    $$
        \gamma_i p = p_{i-1}', p_{i-2}', \dots, p_1', p_0', p_{i+1}', p_{i+2}', \dots, p_{n-1}'
    $$
    $$
        p_j' = \begin{cases}
            p_j     & \text{wenn } p_j < p_i \\
            p_j - 1 & \text{wenn } p_j > p_i
        \end{cases}
        \quad 0 \le j \le n - 1, j \ne i
    $$
\end{definition}
$\gamma_i p$ bezeichnet also die Permutation der Länge $n - 1$, die man erhält, wenn die ersten $i+1$ Elemente von $p$ umgekehrt werden und anschließend das erste entfernt wird. Um tatsächlich eine Permutation der Länge $n - 1$ zu erhalten, werden durch $\gamma_i$ außerdem alle Elemente von $p$, die größer als $p_i$ sind, um 1 verkleinert. Das erhält die relative Ordung der Elemente, sodass die optimale Folge an Wende-und-Ess-Operationen unverändert bleibt. Zum Beispiel, wenn $p = 3, 0, 1, 2$, dann ist
$$
    \gamma_2 p = \gamma_2 (3, 0, 1, 2) = 0, 2, 1
$$
Um später das in Teilaufgabe a$)$ vorliegende Problem klar benennen zu können, wird ihm der Name ``$\gamma_i$-Pancake Sort'' gegeben. $I^n$ bezeichnet die identische Permutation der Länge $n$.

\begin{definition}[$\gamma_i$-Pancake Sort]
    Gegeben sei eine Permutation $p$ der ersten $n$ natürlichen Zahlen. Das Problem, eine kürzestmögliche Folge an $\gamma_i$-Operationen $\gamma_{i_0}, \gamma_{i_1}, \dots \gamma_{i_{k-1}}$ zu finden, sodass
    \begin{align*}
        (\gamma_{i_{k-1}} \dots (\gamma_{i_1} (\gamma_{i_0} p)) \dots) = I^{n - k}
    \end{align*}
    wird $\gamma_i$-Pancake Sort genannt. Das kleinstmögliche $k$ wird als $A(p)$ bezeichnet.
\end{definition}

\subsection{Der Pancake-Graph}

Im Kontext des ursprünglichen Pancake-Sort ist der sogenannte Pancake-Graph für Permutationen der Länge $n$ wie folgt definiert: Für jede Permutation der Länge $n$ gibt es genau einen Knoten, und zwischen den Knoten zweier Permutationen verläuft genau dann eine ungerichtete Kante, wenn sie durch das Umkehren eines Präfixes ineinander umgewandelt werden können. Analog dazu kann man einen Pancake-Graphen $G_n$ für das vorliegende Problem definieren: Jeder Permutation der Länge $n$ oder kleiner wird ein Knoten zugeordnet, und zwischen zwei Permutationen $p$ und $q$ wird eine von $p$ nach $q$ gerichtete Kante eingefügt, wenn $\gamma_i p = q$, für irgendein $0 \le i \le |p|-1$. $G_n$ ist also ein gerichteter, azyklischer Graph (DAG) mit $n$ ``Ebenen'', für jede Permutationslänge eine. Kanten verlaufen nur zur direkt folgenden Ebene, da $\gamma_i$ die Länge um genau 1 reduziert. In Abbildung 1 ist $G_4$ dargestellt, aufgrund seiner Größe wurde er auf 2 Seiten aufgeteilt und Knoten der kleinern Permutationen dupliziert. Die Knoten sind jeweils in lexikographischer Ordung von oben nach unten angeordnet. In diesem Abschnitt soll eine interessante Symmetrieeigenschaft von $G_n$ behandelt werden, die eine Optimierung der Lösungen für beide Teilaufgaben ermöglicht.

Betrachtet man die beiden Teile von $G_4$ gleichzeitig, fällt auf, dass der zweite Teil genau wie der erste Teil aussieht, nur vertikal gespiegelt. Auch die kleineren Pancake-Graphen $G_3, G_2$ und $G_1$, die Teilgraphen von $G_4$ sind, scheinen symmetrisch um ihre Mitte zu sein. Genauer sind die Kanten symmetrisch um die Mitte der lexikographisch sortierten Liste der Permutationen von Größe 4.

\newpage
\begin{tikzpicture}[node distance = {19mm}, main/.style = {draw, circle}]
    \node[main](0123) at (0, 0) {0123};
    \node[main](0132) [below of = 0123] {0132};
    \node[main](0213) [below of = 0132] {0213};
    \node[main](0231) [below of = 0213] {0231};
    \node[main](0312) [below of = 0231] {0312};
    \node[main](0321) [below of = 0312] {0321};

    \node[main](1023) [below of = 0321] {1023};
    \node[main](1032) [below of = 1023] {1032};
    \node[main](1203) [below of = 1032] {1203};
    \node[main](1230) [below of = 1203] {1230};
    \node[main](1302) [below of = 1230] {1302};
    \node[main](1320) [below of = 1302] {1320};

    \node[main](012) at (7, -5.8) {012};
    \node[main](021) [below of = 012] {021};
    \node[main](102) [below of = 021] {102};
    \node[main](120) [below of = 102] {120};
    \node[main](201) [below of = 120] {201};
    \node[main](210) [below of = 201] {210};

    \node[main](01) at (11, -9.6) {01};
    \node[main](10) [below of = 01] {10};

    \node[main](0) at (13.5, -10.5) {0};

    \draw[->](0123) -- (012);
    \draw[->](0123) -- (102);
    \draw[->](0123) -- (210);

    \draw[->](0132) -- (021);
    \draw[->](0132) -- (102);
    \draw[->](0132) -- (210);

    \draw[->](0213) -- (102);
    \draw[->](0213) -- (012);
    \draw[->](0213) -- (120);

    \draw[->](0231) -- (120);
    \draw[->](0231) -- (021);
    \draw[->](0231) -- (201);
    \draw[->](0231) -- (210);

    \draw[->](0312) -- (201);
    \draw[->](0312) -- (012);
    \draw[->](0312) -- (120);

    \draw[->](0321) -- (210);
    \draw[->](0321) -- (021);
    \draw[->](0321) -- (201);
    \draw[->](0321) -- (120);

    \draw[->](1023) -- (012);
    \draw[->](1023) -- (201);

    \draw[->](1032) -- (021);
    \draw[->](1032) -- (012);
    \draw[->](1032) -- (201);

    \draw[->](1203) -- (102);
    \draw[->](1203) -- (021);

    \draw[->](1230) -- (120);
    \draw[->](1230) -- (210);

    \draw[->](1302) -- (201);
    \draw[->](1302) -- (102);
    \draw[->](1302) -- (021);

    \draw[->](1320) -- (210);
    \draw[->](1320) -- (120);

    \draw[->](012) -- (01);
    \draw[->](012) -- (10);
    \draw[->](021) -- (10);
    \draw[->](021) -- (01);
    \draw[->](102) -- (01);
    \draw[->](120) -- (10);
    \draw[->](201) -- (01);
    \draw[->](201) -- (10);
    \draw[->](210) -- (01);
    \draw[->](210) -- (10);

    \draw[->](01) -- (0);
    \draw[->](10) -- (0);
\end{tikzpicture}
\newpage
\begin{tikzpicture}[node distance = {19mm}, main/.style = {draw, circle}]
    \node[main](2013) at (0, 0) {2013};
    \node[main](2031) [below of = 2013] {2031};
    \node[main](2103) [below of = 2031] {2103};
    \node[main](2130) [below of = 2103] {2130};
    \node[main](2301) [below of = 2130] {2301};
    \node[main](2310) [below of = 2301] {2310};

    \node[main](3012) [below of = 2310] {3012};
    \node[main](3021) [below of = 3012] {3021};
    \node[main](3102) [below of = 3021] {3102};
    \node[main](3120) [below of = 3102] {3120};
    \node[main](3201) [below of = 3120] {3201};
    \node[main](3210) [below of = 3201] {3210};

    \node[main](012) at (7, -5.8) {012};
    \node[main](021) [below of = 012] {021};
    \node[main](102) [below of = 021] {102};
    \node[main](120) [below of = 102] {120};
    \node[main](201) [below of = 120] {201};
    \node[main](210) [below of = 201] {210};

    \node[main](01) at (11, -9.6) {01};
    \node[main](10) [below of = 01] {10};

    \node[main](0) at (13.5, -10.5) {0};

    \draw[->](2013) -- (012);
    \draw[->](2013) -- (102);

    \draw[->](2031) -- (021);
    \draw[->](2031) -- (120);
    \draw[->](2031) -- (201);

    \draw[->](2103) -- (102);
    \draw[->](2103) -- (012);

    \draw[->](2130) -- (120);
    \draw[->](2130) -- (201);

    \draw[->](2301) -- (201);
    \draw[->](2301) -- (210);
    \draw[->](2301) -- (021);

    \draw[->](2310) -- (210);
    \draw[->](2310) -- (021);

    \draw[->](3012) -- (012);
    \draw[->](3012) -- (201);
    \draw[->](3012) -- (021);
    \draw[->](3012) -- (102);

    \draw[->](3021) -- (021);
    \draw[->](3021) -- (210);
    \draw[->](3021) -- (102);

    \draw[->](3102) -- (102);
    \draw[->](3102) -- (201);
    \draw[->](3102) -- (021);
    \draw[->](3102) -- (012);

    \draw[->](3120) -- (120);
    \draw[->](3120) -- (210);
    \draw[->](3120) -- (102);

    \draw[->](3201) -- (201);
    \draw[->](3201) -- (120);
    \draw[->](3201) -- (012);

    \draw[->](3210) -- (210);
    \draw[->](3210) -- (120);
    \draw[->](3210) -- (012);

    \draw[->](012) -- (01);
    \draw[->](012) -- (10);
    \draw[->](021) -- (10);
    \draw[->](021) -- (01);
    \draw[->](102) -- (01);
    \draw[->](120) -- (10);
    \draw[->](201) -- (01);
    \draw[->](201) -- (10);
    \draw[->](210) -- (01);
    \draw[->](210) -- (10);

    \draw[->](01) -- (0);
    \draw[->](10) -- (0);
\end{tikzpicture}
\begin{figure}
    \caption{Der Pancake-Graph $G_4$. Von Knoten $u$ verläuft genau dann eine gerichtete Kante nach Knoten $v$, wenn die zu $u$ zugehörige Permutation durch ein $\gamma_i$ in die zu $v$ zugehörige Permutation umgewandelt werden kann.}
\end{figure}
\newpage

Wenn man $G_4$ an einem Stück ohne Duplikation von Knoten zeichnen würde, wäre tatsächlich der gesamte Graph achsensymmetrisch um seine Mitte. Dass die Symmetrie bei $G_1, G_2, G_3$ und $G_4$ auftritt, lässt vermuten, dass sie für $G_n$, mit $n \ge 1$, allgemein gilt.
Bei genauerer Betrachtung des Effekts von $\gamma_i$ auf zwei zur Mitte symmetrisch liegende Permutationen fällt noch eine stärkere Eigenschaft auf. Wir betrachten als Beispiel die zwei symmetrisch liegenden Permutationen $p = 0,2,3,1$ und $p^* = 3, 1, 0, 2$:
\begin{align*}
    \gamma_0 p = 1, 2, 0 \quad \gamma_0 p^* = 1, 0, 2 \\
    \gamma_1 p = 0, 2, 1 \quad \gamma_1 p^* = 2, 0, 1 \\
    \gamma_2 p = 2, 0, 1 \quad \gamma_2 p^* = 0, 2, 1 \\
    \gamma_3 p = 2, 1, 0 \quad \gamma_3 p^* = 0, 1, 2
\end{align*}
Die Ergebnisse der jeweiligen Anwendung von $\gamma_i$ liegen symmetrisch um die Mitte der Liste aller Permutationen von Länge 3. Mithilfe des Programms \emph{test\_sym.cpp} konnte diese Eigenschaft von $\gamma_i$ für alle symmetrisch gelegenen Paare an Permutationen bis Größe 10 bestätigt werden. Es scheint also, dass die Symmetrie des Pancake-Graphen allgemein gültig ist.

Um diese Vermutung zu beweisen, sind einige weitere Mittel nötig. Zunächst wird das fakultätsbasierte Zahlensystem eingeführt, mithilfe dessen der Effekt des $\gamma_i$-Operators aus einer völlig anderen Perspektive betrachtet werden kann. Denn das fakultätsbasierte Zahlensystem erlaubt es, die Anzahl an Inversionen symmetrisch gelegener Paare von Permutationen miteinander in Verbindung zu bringen. Damit kann schließlich gezeigt werden, dass die Anwendung von $\gamma_i$ auf zwei in einer lexikographisch sortierten Liste symmetrisch positionierte Permutationen wieder zu einem symmetrischen Paar führt.
\bigskip

\noindent \emph{Das fakultätsbasierte Zahlensystem.} Im fakultätsbasierten Zahlensystem wird im Gegenstz zum Dezimal- oder Binärsystem eine unterschiedliche Basis für jede Ziffer verwendet. Die $k$-te Ziffer (mit 0 beginnend), von rechts gelesen, verwendet $k!$ als Basis und kann die Werte 0 bis $k$ annehmen. Der Wert einer fakultätsbasiert geschriebenen Zahl ist die Summe der einzelnen Ziffern, multipliziert mit ihrer jeweiligen Basis. Beispielsweise ist
\begin{align*}
    17_{10} & = 2210_!   = 2 \cdot 3! + 2 \cdot 2! + 1 \cdot 1! + 0 \cdot 0!             \\
    24_{10} & = 10000_! = 1 \cdot 4! + 0 \cdot 3! + 0 \cdot 2! + 0 \cdot 1! + 0 \cdot 0! \\
    23_{10} & = 3210_!  = 3 \cdot 3! + 2 \cdot 2! + 1 \cdot 1! + 0 \cdot 0!
\end{align*}
wobei das tiefgestellte ! auf das fakultätsbasierte Zahlensystem hinweist. Eine Fakultät $n!$, geschrieben im fakultätsbasierten Zahlensystem, ist immer von der Form $1000\dots$ ($n$ Nullen). Die Ziffern von $n! - 1$ sind immer genau $n-1, n-2, n-3, \dots, 0$.
Da sich mit einer fakultätsbasierten Zahl mit $n$ Ziffern genau $n!$ Zahlen darstellen lassen, können diese Zahlen auf natürlichem Weg zum Nummerieren von Permutationen der Länge $n$ verwendet werden. Folgende zwei Arten der Nummerierung sind entscheidend den Beweis der Symmetrie des Pancake-Graphen. Beide bilden eine Bijektion zwischen Permutationen der Länge $n$ und ganzen Zahlen von 0 bis $n! - 1$.

\begin{definition}
    Mit $\mu(p)$ wird der Index der Permutation $p$ in einer \emph{lexikographisch aufsteigend} sortierten Folge aller Permutationen der Länge $|p|$ bezeichnet. Mit $\mu(p)_i$ wird die $i$-te Ziffer (beginnend von links) von $\mu(p)$, geschrieben im fakultätsbasierten Zahlensystem, bezeichnet.
\end{definition}

$\mu(p)$ ist auch als Lehmer-Code von $p$ bekannt \cite{factorial}.

\begin{definition}
    Mit $\nu(p)$ wird der Index der Permutation $p$ in einer \emph{kolexikographisch absteigend} sortierten Folge aller Permutationen der Länge $|p|$ bezeichnet. Mit $\nu(p)_i$ wird die $i$-te Ziffer (beginnend von links) von $\nu(p)$, geschrieben im fakultätsbasierten Zahlensystem, bezeichnet.
\end{definition}

Bei Sortierung nach kolexikographischer Ordung werden die Permutationen von rechts anstatt von links beginnend verglichen \cite{lexicographic}.

Für $\mu(p)$ und $\nu(p)$ gelten folgende Eigenschaften: $\mu(p)_i$ ist genau die Anzahl an kleineren Elementen rechts von $p_i$, und $\nu(p)_{|p| - i - 1}$ die Anzahl an größeren Elementen links von $p_i$ \cite{factorial}. Mit $\mu(p)$ ist es nun möglich, die zu $p$ symmetrisch gelegene Permutation zu definieren.

\begin{definition}
    Sei $p$ eine Permutation der Länge $n$. $p^*$ bezeichnet die Permutation, sodass $\mu(p) = n! - \mu(p^*) - 1$.
\end{definition}

$p$ und $p^*$ werden auch als symmetrisches Paar von Permutationen bezeichnet. Zum Beweis der Symmetrie von $G_n$ soll gezeigt werden, dass $\mu(\gamma_i p) + \mu(\gamma_i p^*) = (n - 1)! - 1$ ist. Denn daraus folgt direkt, dass $\gamma_i p$ und $\gamma_i p^*$ wieder ein symmetrisches Paar von Permutationen ist. Die Strategie ist, zunächst zu zeigen, dass wenn ein Präfix zweier symmetrisch gelegener Permutationen umgekehrt wird, wieder zwei symmetrisch gelegene Permutationen entstehen. Dafür wird allerdings noch folgendes Lemma benötigt.

\begin{lemma}
    Sei $p$ eine Permutation der Länge $n$ und $p_i$ ein Element von $p$ $(0 \le i \le n - 1)$. Für jedes $0 \le j \le n-1, j \ne i$ ist entweder ($p_i < p_j$ und $p^*_i > p^*_j$) oder ($p_i > p_j$ und $p^*_i < p^*_j$).
\end{lemma}

\begin{proof}
    In anderen Worten sagt Lemma 1, dass die kleineren, rechts bzw. links gelegenen Elemente von $p_i$ und $p^*_i$ alle an unterschiedlichen Positionen liegen. Für jede Position $j$ ist also entweder $p_i$ und $p_j$ oder $p^*_i$ und $p^*_j$ eine Inversion. Zunächst soll eine etwas schwächere Eigenschaft gezeigt werden, die für den Beweis nötig ist.

    Aufgrund der Definition von $p^*$ gilt
    \begin{align*}
        \mu(p) + \mu(p^*) & = n! - 1                                                                           \\
                          & =(n - 1) \cdot (n - 1)! + (n - 2) \cdot (n - 2)! + \dots + 1 \cdot 1! + 0 \cdot 0!
    \end{align*}
    Die Koeffizienten der Fakultäten in der zweiten Zeile sind genau die Ziffern von $\mu(p) + \mu(p^*)$ in fakultätsbasierter Schreibweise, daher gilt
    \begin{align*}
        \mu(p)_i + \mu(p^*)_i = n - i - 1 \quad 0 \le i \le n - 1
    \end{align*}
    Ist das nicht der Fall, ist es leicht zu überprüfen, dass $\mu(p) + \mu(p^*) \ne n! - 1$. Daher muss die Anzahl an kleineren, rechts gelgenen Elementen von $p_i$ plus der Anzahl an kleineren, rechts gelegenen Elementen von $p^*_i$ genau $n-i-1$ sein. Mit ähnlicher Begründung kann gezeigt werden, dass $\nu(p)_i + \nu(p^*)_i = i$, folglich ist die Anzahl an größeren, links gelegenen Elementen von $p_i$ plus der Anzahl an größeren, links gelegenen Elementen von $p^*_i$ genau $i$. Die Anzahl an links gelegenen, größeren und rechts gelegenen, kleineren Elementen von $p_i$ und $p^*_i$ zusammengezählt ist also allein anbhängig von $i$ und unabhängig davon, welche Permutation $p$ ist.

    Nun wird der eigentliche Beweis durchgeführt, er funktioniert über unendlichen Abstieg. Man nehme an, dass für irgendein $j_0 > i$ sowohl $p_{j_0} < p_i$, als auch $p^*_{j_0} < p^*_i$ gilt. Der Fall $j_0 < i$ funktioniert ähnlich. Auch die Annahme $p_{j_0} < p_i$ und $p^*_{j_0} < p^*_i$ dient nur der einfacheren Beweisführung, der Fall $p_{j_0} > p_i$ und $p^*_{j_0} > p^*_i$ kann mit der gleichen Methode bewiesen werden. Da $\nu(p)_{n - j_0 - 1} + \nu(p^*)_{n - j_0 - 1} = j_0$, muss für irgendein ein $j_1 < j_0$ gelten, dass $p_{j_1} < p_{j_0}$ und $p^*_{j_1} < p^*_{j_0}$. Andernfalls wäre es nicht möglich, auf insgesamt $j_0$ links gelegene, größere Elemente von $p_{j_0}$ und $p^*_{j_0}$ zu kommen. Nun gibt es zwei Fälle:
    \begin{enumerate}
        \item $j_1 < i$: Rechts von $j_1$ liegen $i$ und $j_0$, das heißt, es muss zwei Indizes $j_2, j_3 > j_1$ geben, sodass $p_{j_2} < p_{j_1}$ und $p^*_{j_2} < p^*_{j_1}$, $p_{j_3} < p_{j_1}$ und $p^*_{j_3} < p^*_{j_1}$. Andernfalls wäre es wieder nicht möglich, auf die nötigen $\mu(p)_{j_1} + \mu(p^*)_{j_1} = n - j_1 - 1$ nötigen, kleineren, rechts gelegenen Elemente zu kommen. Denn bereits zwei der $n - j_1 - 1$ rechts gelegenen Plätze sind sowohl in $p$ als auch in $p^*$ durch größere Zahlen besetzt, aber $n - j_1 - 1$ kleinere Elemente sind erforderlich.
        \item $i < j_1 < j_0$: Da $p_{j_1} < p_{j_0}$ und $p^*_{j_1} < p^*_{j_0}$, muss es rechts von $j_1$ einen Index $j_2 > j_1$ geben, sodass $p_{j_2} < p_{j_1}$ und $p^*_{j_2} < p^*_{j_1}$. Auch links von $j_1$ muss es einen Index $j_3 < j_1$ geben, sodass $p_{j_3} < p_{j_1}$ und $p^*_{j_3} < p^*_{j_1}$. Erneut wäre andernfalls das Erreichen der nötigen $\mu(p)_{j_1} + \mu(p^*)_{j_1} = n - j_1 - 1$ rechts gelegenen, kleineren und der $\nu(p)_{n - j_1 - 1} + \nu(p^*)_{n - j_1 - 1} = j_1$ links gelegenen, größeren Elemente unmöglich.
    \end{enumerate}
    Man sieht, dass durch die Forderung nach einer allein vom Index anbhängigen Zahl rechts gelegener, kleinerer bzw. links gelegener, größerer Elemente immer kleinere Zahlen in $p$ und $p^*$ gezwungen werden. Um diese herum sind aber nur größere Elemente, wodurch wieder kleinere Zahlen zum Ausgleich nötig werden. Dieser Prozess endet niemals, da mit jedem Schritt immer noch kleinere Zahlen erzeugt werden. Das ist ein Widerspruch, da natürliche Zahlen, wie sie in einer Permutation vorkommen, nicht unendlich oft verringert werden können. Das zeigt, dass die Annahme $p_{j_0} < p_i$ und $p^*_{j_0} < p^*_i$ falsch war.
\end{proof}

Für eine Permutation $p$ und $0 \le i, j, k \le n - 1$ wird nun die Funktion $\eta(p, i, j, k)$ definiert.
$$
    \eta(p, i, j, k) = \sum_{h = j}^k
    \begin{cases}
        1 & \text{wenn } p_i > p_h   \\
        0 & \text{wenn } p_i \le p_h
    \end{cases}
$$
$\eta(p, i, j, k)$ zählt die Anzahl an Elementen mit Indizes in $[j, k]$, die kleiner als $p_i$ sind. Lemma 1 ermöglicht es, die Summe von $\eta$ für $p$ und $p^*$ einfach zu berechnen, denn für jeden Index ist entweder das Element in $p$ oder in $p^*$ kleiner als $p_i$ bzw. $p^*_i$.
\begin{align*}
    \eta(p, i, j, k) + \eta(p^*, i, j, k) & = \sum_{h = j}^k
    \begin{cases}
        1 & \text{wenn } p_i > p_h   \\
        0 & \text{wenn } p_i \le p_h
    \end{cases} + \sum_{h = j}^k
    \begin{cases}
        1 & \text{wenn } p^*_i > p^*_h   \\
        0 & \text{wenn } p^*_i \le p^*_h
    \end{cases}                                 \\
                                          & = \sum_{h = j}^k \Bigg (
    \begin{cases}
            1 & \text{wenn } p_i > p_h   \\
            0 & \text{wenn } p_i \le p_h
        \end{cases} +
    \begin{cases}
            1 & \text{wenn } p^*_i > p^*_h   \\
            0 & \text{wenn } p^*_i \le p^*_h
        \end{cases} \Bigg )                                 \\
                                          & = \sum_{h = j}^k 1       \\
                                          & = k - j + 1
\end{align*}
Damit kann nun gezeigt werden, dass das Umkehren von Präfixen zweier symmetrisch gelegener Permutationen erneut zu zwei symmetrisch gelegene Permutationen führt. Das ist fast das gewünschte Ergebnis, es muss lediglich noch das erste Element aus beiden Permutationen entfernt werden.
\begin{lemma}Seien $x$ und $y$ die Permutationen, die aus $p$ und $p^*$ durch Umkehrung des Präfixes bis einschließlich Index $i$ hervorgehen. Wenn $\mu(p) + \mu(p^*) = n! - 1$, dann gilt auch $\mu(x) + \mu(y) = n! - 1$.
\end{lemma}

\begin{proof}
    Die Ziffern $\mu(p)$ und $\mu(p^*)$ geben in fakultätsbasierter Schreibweise die Anzahl an rechts gelegenen, kleineren Elementen an. Da an den Elementen $p_j, p^*_j$ für $j > i$ nichts geändert wird, ändert sich auch nicht ihre Zahl rechts gelegener, kleinerer Elemente, d. h. sie können im Folgenden außer Acht gelassen werden. Für $j < i$ werden alle links gelegenen, kleineren Elemente durch die Umkehrung auf die rechte Seite gebracht, die kleineren Elemente rechts von $i$ bleiben. Der Index, zu dem das $j$-te Element durch die Umkehrung bewegt wird, ist $i - j$. Folglich ist die Anzahl rechts gelegener, kleinerer Elemente von $x_{i - j}$ und $y_{i - j}$ zusammen
    \begin{align*}
        \mu(x)_{i - j} + \mu(y)_{i - j}
         & =  \eta(p, j, 0, j - 1) + \eta(p, j, i + 1, n - 1)            \\
         & \quad + \eta(p^*, j, 0, j - 1) + \eta(p^*, j, i + 1, n - 1)   \\
         & =  \eta(p, j, 0, j - 1) + \eta(p^*, j, 0, j - 1)              \\
         & \quad + \eta(p, j, i + 1, n - 1) + \eta(p^*, j, i + 1, n - 1) \\
         & =  (j - 1 - 0 + 1) + (n - 1 - (i + 1) + 1)                    \\
         & =  j + n - i - 1                                              \\
         & =  n - (i - j) - 1
    \end{align*}
    Daraus folgt
    \begin{align*}
        \mu(x)_i + \mu(y)_i = n - i - 1 \quad 0 \le i \le n - 1
    \end{align*}
    und damit
    \begin{align*}
        \mu(x) + \mu(y) = n! - 1
    \end{align*}
\end{proof}

Man sieht, dass das Umkehren eines Präfixes in einem symmetrischen Paar von Permutationen wieder zu einem symmetrischen Paar führt. Nun kann die Symmetrie des Pancake-Graphen, bzw. des $\gamma_i$-Operators als Satz festgehalten werden.

\begin{theorem}
    Wenn $p$ eine Permutation der Länge $n$ und $q$ eine Permutation der Länge $n - 1$ ist, gilt
    $$
        \gamma_i p = q \Longleftrightarrow \gamma_i p^* = q^* \quad 0 \le i \le n - 1
    $$
\end{theorem}

\begin{proof}
    Wir nennen die Permutation, die man durch Umkehren des Präfixes bis $i$ von $p$ erhält, $x$. Aufgrund von Lemma 2 ist $x^*$ genau die Permutation, die man durch Umkehren des Präfixes bis $i$ von $p^*$ erhält.
    Da
    \begin{align*}
        \gamma_i p = x_1, x_2, \dots, x_{n-1} \\
        \gamma_i p^* = x^*_1, x^*_2, \dots, x^*_{n-1}
    \end{align*}
    entspricht die Anzahl rechts gelegener, kleinerer Elemente von $(\gamma_i p)_0, (\gamma_i p)_1, \dots, (\gamma_i p)_{n - 2}$ bzw. $(\gamma_i p^*)_0, (\gamma_i p^*)_1, \dots, (\gamma_i p^*)_{n - 2}$ genau der Anzahl rechts gelegener, kleinerer Elemente von $x_1, x_2, \dots, x_{n-1}$ bzw. $x^*_1, x^*_2, \dots, x^*_{n-1}$. Daher gilt
    \begin{align*}
        \mu(\gamma_i p)_i = \mu(x)_{i + 1} \\
        \mu(\gamma_i p^*)_i = \mu(x^*)_{i + 1}
    \end{align*}
    und folglich
    \begin{align*}
        \mu(\gamma_i p)_i + \mu(\gamma_i p^*)_i & = \mu(x)_{i + 1} + \mu(x^*)_{i + 1} \\
                                                & = (n - (i + 1) - 1)                 \\
                                                & = (n - 1) - i - 1
    \end{align*}
    Da $|\gamma_i p| = |\gamma_i p^*| = n - 1$, ist $\gamma_i p$ und $\gamma_i p^*$ ein symmetrisches Paar von Permutationen der Länge $n - 1$. Somit gilt $\gamma_i p = q$ genau dann, wenn $\gamma_i p^* = q^*$.
\end{proof}

\subsection{Reduktion des Burnt Pancake-Problems}

In diesem Abschnitt soll gezeigt werden, dass $\gamma_i$-Pancake Sort mindestens so schwierig wie das Burnt Pancake Problem, eine Variante des Pfannkuchen-Sortierproblems, ist. Mit ``mindestens so schwierig'' ist gemeint, dass das Burnt Pancake Problem in polynomieller Zeit auf das vorliegende Problem reduziert werden kann. Damit wird gezeigt, dass wahrscheinlich kein Algorithmus existiert, der $\gamma_i$-Pancake Sort in polynomieller Zeit löst. Für das Burnt Pancake-Problem gibt es zwar keinen Beweis der NP-Schwere, allerdings ist es seit über 40 Jahren niemandem gelungen, einen Algorithmus mit polynomieller Laufzeit für dieses Problem zu entwickeln.

Im Burnt Pancake Problem haben Pfannkuchen eine verbrannte Seite, die nach dem Sortieren bei jedem Pfannkuchen unten liegen muss \cite{burntpancakes}. Das Konzept der verbrannten Seite wird in folgender Definition durch ein Vorzeichen vor jedem Element der Permutation formalisiert.
\begin{definition}[Burnt Pancake-Problem]
    Gegeben sei eine vorzeichenbehaftete Permutation
    \begin{align*}
        p = \sigma_0 p_0, \sigma_1 p_1, \dots, \sigma_{n-1} p_{n-1}
    \end{align*}
    wobei $0 \le p_i \le n-1$ und $\sigma_i \in \{-1, 1\}$ für $0 \le i \le n - 1$ sowie $p_i \ne p_j$ für $i \ne j$. Wir nennen folgendes Problem das Burnt Pancake-Problem: Was ist die minimale Anzahl an Präfixumkehrungen, wobei bei einer Präfixumkehrung auch alle Vorzeichen im umgekehrten Präfix invertiert werden, sodass $p$ in $I^n$ überführt wird und alle Vorzeichen positiv sind?
\end{definition}
$\sigma_i = -1$ bedeutet, dass der $i$-te Pfannkuchen die verbrannte Seite oben hat, andernfalls liegt die unverbrannte Seite oben.

\begin{theorem}
    $\gamma_i$-Pancake Sort ist mindestens so schwierig wie das Burnt Pancake-Problem.
\end{theorem}

\begin{proof}
    Schon das Bestimmen der minimalen Anzahl an $\gamma_i$-Operationen ist mindestens so schwierig wie das Burnt Pancake-Problem, was im Beweis gezeigt wird. Daraus folgt direkt, dass auch $\gamma_i$-Pancake Sort mindestens so schwierig ist, denn mit jedem Algorithmus, der $\gamma_i$-Pancake Sort löst, kann man einfach die minimale Anzahl an $\gamma_i$-Operationen bestimmen.

    Die Reduktion geschieht nun, indem das Burnt Pancake-Problem in $\gamma_i$-Pancake Sort simuliert wird. Für eine vorzeichenbehaftete Permutation $p$ der Länge $n$, die Eingabe für das Burnt Pancake-Problem, konstruieren wir eine nicht-vorzeichenbehaftete Permutation $q$ wie folgt:
    $$
        q = a_0, a_1, \dots, a_{n-1}
    $$
    $$
        a_i  = \begin{cases}
            (p_i - 1) \cdot 3n + 1, (p_i - 1) \cdot 3n + 2, \dots, p_i \cdot 3n & \text{wenn } \sigma_i = 1  \\
            p_i \cdot 3n, p_i \cdot 3n - 1, \dots, (p_i - 1) \cdot 3n + 1       & \text{wenn } \sigma_i = -1
        \end{cases}
    $$
    Jedem Pfannkuchen in $p$ wird je nach seiner Orientierung eine aufsteigende oder absteigende Folge von $3n$ aufeinanderfolgenden, natürlichen Zahlen zugeordnet. Dieses Vorgehen ist in Abbildung 2 veranschaulicht. Mit $a_i$ wird die zu $p_i$ zugehörige Teilfolge von $q$ bezeichnet. Der Einfachheit halber bezeichnet $a_i$ auch die zu $p_i$ zugehörige Teilfolge in $q$ nach einigen Sortierschritten, auch wenn diese dann andere Zahlen enthalten kann bzw. gekürzt worden sein kann. Die Folgen $a_0, a_1, \dots, a_{n-1}$ in Zeile 1 werden zu einer Folge $q$ zusammengefügt, $q$ ist also keine Folge von Folgen. Die Länge von $q$ beträgt $n \cdot 3n = 3n^2$, ist also durch ein Polynom in $n$ beschränkt, d. h. die Reduktion ist eine Polynomialzeitreduktion.

    \begin{figure}[h]
        \centering
        \includegraphics[width=\textwidth]{grafiken/burnt-pancake-reduktion-1}
        \caption{Reduktion des Burnt Pancake-Problems auf $\gamma_i$-Pancake Sort. Die Pfeile geben die Orientierung der verbrannten Pfannkuchen an, die Pfeilspitze zeigt zur nicht verbrannten Seite.}
    \end{figure}
    Ist $\sigma_i = 1$, d. h. der $i$-te Pfannkuchen ist richtig orientiert, wird er durch eine aufsteigende Folge repräsentiert. Das entspricht auch der richtigen Orientierung im Sortieren ohne Vorzeichen. Denn wäre $p$ vollständig sortiert und $\sigma_i = 1$ für alle $0 \le i \le n - 1$, wäre auch $q$ vollständig sortiert. Die Idee ist nun, zu zeigen, dass kein $a_i$ in einer optimalen Folge an $\gamma_i$-Operationen in der Mitte getrennt oder vollständig aufgegessen wird. Denn dann werden durch $\gamma_i$-Operationen immer nur Pfannkuchen am Anfang und Ende einer der Folgen $a_i$ entfernt, sodass sich diese schließlich wie ein verbrannter Pfannkuchen verhalten. Durch die $3n$ Pufferelemente bleiben von jedem $a_i$ außerdem mindestens $n$ Elemente übrig, sodass das Ergebnis des Sortierens mit $\gamma_i$ als sortierter Stapel an verbrannten Pfannkuchen interpretiert werden kann.

    Die einem Element von $p$ zugeordnete Teilfolge von $q$ wird niemals durch eine optimale Folge an $\gamma_i$-Operationen vollständig entfernt, da eine vorzeichenbehaftete Permutation in maximal $2n$ Schritten sortiert werden kann. Diese obere Schranke stammt von Cohen und Blum \cite{burntpancakes}. Für $n \ge 10$ wurde dort sogar eine Schranke von $2n - 2$ angegeben, der Einfachheit halber wird im Folgenden allerdings mit $2n$ gearbeitet. Es folgt, dass eine Folge an $\gamma_i$-Operationen, die länger als $2n$ ist, nicht optimal sein kann, denn man könnte $q$ in maximal $2n$ Schritten sortieren, indem man eine optimale Folge an Präfixumkehrungen für $p$ simuliert. Wenn in $p$ das Präfix bis Index $i$ umgekehrt wird, wendet man $\gamma_j$ auf $q$ an, wobei $j$ die größtmöglich Zahl ist, sodass $q_j$ zur Teilfolge von $p_i$ gehört (unter Beachtung der Tatsache, dass durch jede Anwendung von $\gamma_i$ möglicherweise einige Elemente in $q$ verringert werden). Da jedes Element von $p$ nach der Sortierung positiv ist, sind nach der Definition von $q$ auch alle den Elementen von $p$ zugeordneten Teilfolgen aufsteigend sortiert. Da die Pfannkuchen in $p$ aufsteigend sortiert sind, sind auch die ihnen zugeordneten Teilfolgen in $q$ aufsteigend sortiert, daher lässt sich $q$ tatsächlich in maximal $2n$ Schritten sortieren. Da also maximal $2n$ $\gamma_i$-Operationen durchgeführt werden und mit jeder $\gamma_i$-Operation genau ein Element aus $q$ entfernt wird, muss jedes $a_i$ nach dem Sortieren noch mindestens $n$ Elemente enthalten.

    Nun wird gezeigt, dass es unter den optimalen $\gamma_i$-Folgen zum Sortieren von $q$ immer eine gibt, die im Sortierprozess keines der $a_i$ in der Mitte trennt. Das ist notwendig, da ein solcher Schritt, übertragen auf das Burnt Pancake-Problem, unmöglich wäre. Man nehme an, $a_j$ für $0 \le j \le n - 1$ wird durch $\gamma_k$ mit $l + 1 \le k \le r-1$ in zwei Teile geteilt, wobei $a_j$ vor der Anwendung von $\gamma_k$ in $q$ von $q_l$ bis $q_r$ reichte. Da nach vollständiger Sortierung von $q$ noch Elemente von $a_j$ vorhanden sein müssen, müssen die zwei Teile an einem bestimmten Punkt wieder in richtiger Orientierung zusammengefügt werden. Es ergeben sich zwei Fälle: Entweder wurde einer der Teile vollständig aufgegessen oder beide sind noch vorhanden. Dass beide Teile vollständig aufgegessen werden ist unter der Annahme, dass die behandelte $\gamma_i$-Folge optimal ist, unmöglich. Das Ergebnis im ersten Fall wäre auch erreichbar, indem man immer wieder Elemente vom Anfang oder Ende von $a_j$ entfernt. Im zweiten Fall hätte man anstatt $\gamma_k$ $\gamma_r$ verwenden können und zum gleichen Ergebnis gelangen können, indem man $q_{k + 1}, q_{k + 2}, \dots, q_r$ dauerhaft mit $q_l, q_{l+1}, \dots, q_{k}$ mitführt. Das heißt, man führt alle Wendeoperationen hinter den gleichen $a_i$ wie zuvor durch, behandelt $q_l, q_{l+1}, q_r$ aber genau so wie zuvor $q_l, q_{l+1}, q_{k-1}$. Der genaue Index der $\gamma_i$-Operationen mag sich unterscheiden, da in jedem Schritt aber die gleichen $a_i$ umgekehrt werden, ist das Ergebnis ebenfalls ein sortierter Stapel. Die Argumentation ist in Abbildung 3 veranschaulicht. Durch die Veränderung wird die Gesamtzahl an $\gamma_i$-Operationen nicht vergrößert, daher gibt es immer eine optimale Folge an $\gamma_i$-Operationen ohne Trennung einer Folge $a_i$ in der Mitte.

    \begin{figure}[H]
        \centering
        \includegraphics[width=\textwidth]{grafiken/burnt-pancake-reduktion-2}
        \caption{Eine optimale Folge an $\gamma_i$-Operationen kann immer ohne die Teilung von $a_i$ in der Mitte auskommen.}
    \end{figure}

    Damit verhält sich eine Teilfolge, die einem verbrannten Pfannkuchen zugeordnet wurde, im Sortierprozess wie ein verbrannter Pfannkuchen. Denn sie kann weder vollständig verschwinden oder geteilt werden und muss am Ende, wie der verbrannte Pfannkuchen, richtig orientiert an der richtigen Stelle platziert sein, damit $q$ sortiert ist. Folglich ist die minimale Anzahl an $\gamma_i$-Operationen zum Sortieren von $q$ gleich der minimalen Anzahl an Wendeoperationen zum Sortieren von $p$. Da jede Instanz des Burnt Pancake-Problems in polynomieller Zeit auf eine Instanz von $\gamma_i$-Pancake Sort reduziert werden kann, ist $\gamma_i$-Pancake Sort mindestens so schwierig wie das Burnt Pancake-Problem.
\end{proof}

\subsection{Finden der kürzesten Folge an $\gamma_i$-Operationen}

In diesem Abschnitt werden drei Lösungsverfahren für Teilaufgabe a) entwickelt. Zunächst wird ein Brute-Force Ansatz vorgestellt, der bereits alle vorgegebenen Beispiele gut lösen kann. Anschließend wird eine untere Schranke für die nötige Anzahl an $\gamma_i$-Operationen zum Erreichen einer identischen Permutation hergeleitet, mit der sich der Brtue-Force Algorithmus auf zwei Arten verbessern lässt.
\bigskip

\noindent \emph{Brute-Force Lösung.} Wie der Name bereits sagt, werden einfach alle Möglichkeiten, eine $\gamma_i$-Operation durchzuführen, ausgetestet, also $\gamma_0, \gamma_1, \dots, \gamma_{n-1}$. Wir definieren eine Warteschlange $Q$, die alle noch nicht besuchten Permutationen enthält, die von einer besuchten Permutation durch eine $\gamma_i$-Operation erreicht werden können. Als einzige Ausnahme von dieser Definition enthält $Q$ zu Beginn nur $p$. Für das vordereste Element der Warteschlange $s$ werden alle $|s|$ möglichen $\gamma_i$-Operationen durchgeführt und die Permutationen $\gamma_i s$ für $0 \le i \le |s|$, die noch nicht besucht wurden, zu $Q$ hinzugefügt. Beim Erreichen einer identischen Permutation wird über eine Vorgängerliste die durchgeführte Operationenfolge rekonstruiert und zurückgegeben. Anders gesagt, es wird eine Breitensuche auf dem Pancake-Graphen von $p$ aus durchgeführt und der kürzeste Pfad zu einer identischen Permutation bestimmt. Da der Pancake-Graph ungewichtet ist, kann Breitensuche zum Finden kürzester Pfade verwendet werden.

Die Vorgängerliste wird durch eine Hashmap für jede Permutationslänge realisiert, die bei $\mu(p)$ den $\mu$-Wert des Vorgängers von $p$ speichert. Es wird ein Array von Hashmaps angelegt, das bei Index $k - 1$ die Hashmap für Knoten der Länge $k$ enthält. Um Speicher zu sparen, wird in der Warteschlange außerdem nicht die gesamte Permutation gespeichert, sondern lediglich ihre Länge und ihr $\mu$-Wert, wodurch sie eindeutig bestimmt ist. Wie $\mu(p)$ berechnet und $p$ aus $\mu(p)$ rekonstruiert werden kann, wird später diskutiert. Die Funktion, die eine Permutation $s$ zurückgibt, sodass $\mu(s) = i$ und $|s| = n$, wird im Folgenden einfach mit \textsc{IthPermutation}$(n, i)$ bezeichnet. Der Brute-Force Algorithmus kann als Pseudocode wie folgt zusammengefasst werden.

\begin{algorithm}
    $Q \gets$ Queue containing $(|p|, \mu(p))$ \;
    $pre \gets$ Array of Hashmaps of size $|p|$ \;

    \While{$Q \ne \{\}$}
    {
        $(m, i) \gets $ \textsc{Dequeue}$(Q)$ \;
        $s \gets$ \textsc{IthPermutation}$(m, i)$ \;
        \If{$i = 0$}
        {
            \Return{} \textsc{ReconstructOperations}$(pre, m, i)$ \;
        }

        \For{$j \gets 0$ \KwTo $m - 1$}
        {
            \If{$\mu(\gamma_j s) \notin pre\mathrm{[m - 2]}$}
            {
                $pre[m - 2][\mu(\gamma_j s)] \gets i$ \;
                \textsc{Enqueue}$(Q, (m - 1, \mu(\gamma_j s)))$ \;
            }
        }
    }

    \caption{\textsc{MinOperationsBFS}$(p)$}
\end{algorithm}

\noindent Um die durchgeführten $\gamma_i$-Operationen aus \emph{pre} zu rekonstruieren, wird der aus der Breitensuche entstehende Baum von unten nach oben durchlaufen. Auf dem direkten Vorgänger wird jede mögliche $\gamma_i$-Operation ausprobiert, bis die Richtige gefunden ist.

\begin{algorithm}
    $t \gets$ empty Array \;

    \While{$m < n$}{
        $s \gets$ \textsc{IthPermutation}$(m + 1, pre[m - 1][i])$ \;

        \For{$j \gets 0$ \KwTo $m + 1$}
        {
            \If{$\mu(\gamma_j s) = i$}
            {
                append $j$ to the front of $t$ \;
                \textbf{break} \;
            }
        }

        $i \gets pre[m - 1][i]$ \;
        $m \gets m + 1$ \;
    }
    \Return{t} \;

    \caption{\textsc{ReconstructOperations}$(pre, m, i)$}
\end{algorithm}

\noindent Nun werden die Algorithmen zur Berechnung von $\mu(p)$ und \textsc{IthPermutation} skizziert. Sie werden von Bonet \cite{permutationranking} übernommen, eine formale Beschreibung ist dort zu finden. In dem Artikel wurden mehrere Verfahren zur Abbildung von Permutationen auf Zahlen und umgekehrt vorgestellt. Einige laufen in linearer Zeit, sind aber auf große, vorher erstellte Datenstrukturen angewiesen oder funktionieren nur bis zu einer bestimmten Länge. Daher werden die zwei Verfahren verwendet, die in $\Theta(n \log n)$ Zeit laufen, ohne zusätzliche Datenstrukturen auskommen, und für jede Permutationslänge verwendet werden können.

Zur Berechnung von $\mu(p)$ wird wieder das fakultätsbasierte Zahlensystem zur Hilfe gezogen, indem zunächst die Ziffern von $\mu(p)$ berechnet werden. Dafür wird folgende Eigenschaft verwendet: $\mu(p)_i$ entspricht genau $p_i$ minus der Anzahl links gelegener, kleinerer Elemente in $p$ \cite{permutationranking}. Damit redziert sich das Problem darauf, die Anzahl kleinerer, links gelegener Elemente von $p_i$ zu zählen. Das kann mit einem Segmentbaum in $\Theta(\log n)$ Zeit pro Element gelöst werden, sodass sich insgesamt eine Zeitkomplexität von $\Theta(n \log n)$ ergibt.

Für \textsc{IthPermutation} wird ähnlich vorgegangen. Zunächst werden die Ziffern von $\mu(p)$ im fakultätsbasierten Zahlensystem durch wiederholtes Teilen mit Rest bestimmt. Wie bei der Berechnung der Ziffern einer Zahl im Binärsystem sind die Ziffern die Reste der Folge von Divisionen, nur dass der Divisor nicht konstant ist, sondern zuerst 1, dann 2, 3 und so weiter. Die Indizes von $p$ werden anschließend aufsteigend bearbeitet, man nehme also im Folgenden an, dass $p_i$ gerade bestimmt werden soll und $p_j$ für $j < i$ bereits bekannt ist. Mit der Tatsache, dass $\mu(p)_i$ genau $p_i$ minus der Anzahl kleinerer, links gelegener Elemente ist, reduziert sich das Problem darauf, zu bestimmen, welchen Wert $p_i$ annehmen muss, sodass es genau $\mu(p)_i$ kleinere Elemente links davon gibt. Auch das lässt sich mit einem Segmentbaum in $\Theta(\log n)$ Zeit pro Element lösen. Für ihn gilt folgende Invariante: Ist ein Element $y$ noch nicht aufgetreten, steht eine 1 bei Index $y$, andernfalls eine 0. Zur Bestimmung von $p_i$ wird der Segmentbaum von oben nach unten heruntergelaufen und die Schritte so gewählt, dass die Summe links gelegener Elemente genau $\mu(p)_i$ ist. Aber dadurch landet man genau bei dem $p_i$-ten Element des Segmentbaums, denn links liegen $\mu(p)_i$ Einsen plus die Anzahl bereits aufgetretener, kleinerer Elemente, die im Segmentbaum bereits auf 0 gesetzt wurden. Nun wird auch $p_i$ im Segmentbaum auf 0 gesetzt und so die Invariante erhalten. Insgesamt erhält man auch hier eine Zeitkomplexität von $\Theta(n \log n)$.
\bigskip

\noindent \emph{Eine Unterschranke für $A(p)$.} Mit einer Unterschranke für die Anzahl an benötigten $\gamma_i$-Operationen wird es möglich sein, während der Suche manche Permutationen außer Acht zu lassen, da sie nicht zu einem besseren Ergebnis führen können. Wir betrachten die Anzahl an monoton steigenden oder fallenden Teilstrings in einer Permutation. Ein monoton steigender Teilstring $T$ von Länge $k$ einer Permutation $p$ ist eine Menge an Indizes $\{i, i + 1, \dots, i + k - 1\}$, so, dass $p_{j+1} > p_j$ für $i \le j \le i+ k - 2$ und $T$ bezüglich dieser Eigenschaft maximale Länge hat. Ein monton fallender Teilstring ist ähnlich definiert, nur gilt $p_{j + 1} < p_j$ für $i \le j \le i + k - 2$. Ein monotoner Teilstring ist ein monoton steigender oder fallender Teilstring. Nach dieser Definition ist ein Element von $p$, dessen Nachbarn beide größer oder kleiner sind, Teil von 2 monotonen Teilstrings. Die identische Permutation besteht offensichtlich nur aus einem monoton steigenden Teilstring. Mithilfe von folgendem Lemma kann dann einfach eine untere Schranke für $A(p)$ bestimmt werden.

\begin{lemma}
    Pro $\gamma_i$-Operation kann die Anzahl monotoner Teilstrings einer Permutation $p$ maximal um 3 reduziert werden.
\end{lemma}

\begin{proof}
    Die Anzahl monotoner Teilstrings in $p$ wird im Folgenden $x$ genannt. Die Veränderung von $x$ durch eine $\gamma_i$-Operation wird $\Delta x$ genannt. Zunächst bemerkt man, dass sich die Zahl monotoner Teilstrings nur durch Hinzufügen bzw. Entfernen von Teilstrings, die $p_0$ oder $p_i$ enthalten, verändern kann. Wir unterscheiden zwei Fälle: Entweder ist $p_i$ Teil von zwei oder von einem monotonen Teilstring.

    Im ersten Fall werden wieder einige Fälle unterschieden. Zunächst wird nur der Beitrag zu $\Delta x$ von Teilstrings mit $p_i$ betrachtet.

    \begin{enumerate}
        \item $p_{i + 1}$ ist Teil von zwei monotonen Teilstrings. Das bedeutet, $p_i, p_{i + 1}$ ist ein monotoner Teilstring von Länge 2.
              \begin{enumerate}
                  \item $p_{i - 1}$ ist Teil von zwei monotonen Teilstrings $\Longrightarrow \Delta x = - 2$.
                  \item $p_{i - 1}$ ist Teil von einem monotonen Teilstring $\Longrightarrow \Delta x = - 1$.
              \end{enumerate}
        \item $p_{i + 1}$ ist Teil von einem montonen Teilstring.
              \begin{enumerate}
                  \item $p_{i - 1}$ ist Teil von zwei monotonen Teilstrings $\Longrightarrow \Delta x = - 1$.
                  \item $p_{i - 1}$ ist Teil von einem monotonen Teilstring $\Longrightarrow \Delta x = 0$.
              \end{enumerate}
    \end{enumerate}

    \noindent   Für den Beitrag von $p_0$ werden folgende Fälle unterschieden.

    \begin{enumerate}
        \item $p_0 < p_{i + 1}$
              \begin{enumerate}
                  \item $p_0 < p_1$
                        \begin{enumerate}
                            \item $p_{i + 1} < p_{i + 2} \Longrightarrow \Delta x = 0$
                            \item $p_{i + 1} > p_{i + 2} \Longrightarrow \Delta x = 1$
                        \end{enumerate}
                  \item $p_0 > p_1$
                        \begin{enumerate}
                            \item $p_{i + 1} < p_{i + 2} \Longrightarrow \Delta x = -1$
                            \item $p_{i + 1} > p_{i + 2} \Longrightarrow \Delta x = 0$
                        \end{enumerate}
              \end{enumerate}
        \item $p_0 > p_{i + 1}$ Der Fall ist symmetrisch zu $p_0 < p_{i + 1}$.
    \end{enumerate}

    \noindent Man sieht, dass $\Delta x$ insgesamt nicht kleiner als $-3$ sein kann. Für den Fall, dass $p_i$ Teil von einem monotonen Teilstring ist, muss nur der Beitrag von $p_i$ neu betrachtet werden. Da aber bereits festgestellt wurde, dass nur Teilstrings, die $p_0$ oder $p_i$ enthalten, verschwinden können und $p_i$ nur Teil von einem monotonen Teilstring ist, gilt $\Delta x \ge -1$, sodass in allen Fällen $\Delta x \ge - 3$ ist.

    Bisher wurde implizit angenommen, dass $1 \le i \le n - 3$ gilt, da $p_{i-1}, p_{i + 1}$ und $p_{i + 2}$ in Betracht gezogen wurden. Wenn $i = 1$ oder $i = n - 1$, gilt offensichtlich $\Delta x \in \{0, -1\}$. Wenn $i = n - 2$, gilt $\Delta x \ge -2$, was mit der gleichen Fallunterscheidung wie oben überprüft werden kann.
\end{proof}

\noindent Damit kann nun Folgendes gezeigt werden.

\begin{theorem}
    Sei $x$ die Anzahl monotoner Teilstrings einer Permutation $p$. Dann gilt
    $$ A(p) \ge \bigg{\lfloor} \frac {x + 1} 3 \bigg{\rfloor} $$.
\end{theorem}

\begin{proof}
    Die identische Permutation besitzt genau einen monotonen Teilstring, d. h. durch die $\gamma_i$-Operationen müssen insgesamt $x - 1$ monotone Teilstrings entfernt werden. Wenn $x - 1$ durch 3 teilbar ist, sind dafür nach Lemma 3 mindestens
    \begin{align*}
        \frac {x - 1} 3 = \frac {x - 1} 3 + \bigg{\lfloor} \frac 2 3 \bigg{\rfloor}
        = \bigg{\lfloor} \frac {x - 1} 3 + \frac 2 3 \bigg{\rfloor} =
        \bigg{\lfloor} \frac {x + 1} 3 \bigg{\rfloor}
    \end{align*}
    Operationen nötig. Wenn $x - 1 \equiv 1 \bmod 3$, ist neben den mindestens $(x - 2)/3$ Operationen mit $\Delta x = -3$ noch mindestens eine weitere Operation nötig. Insgesamt ergibt sich eine Unterschranke von
    \begin{align*}
        \frac {x - 2} 3 + 1 = \frac {x - 2} 3 + \frac 3 3 = \frac {x + 1} 3
    \end{align*}
    Für $x - 1 \equiv 2 \bmod 3$ sind mindestens $(x - 3) / 3$ Operationen mit $\Delta x = -3$ und eine weitere erforderlich.
    \begin{align*}
        \frac {x - 3} 3 + 1 = \frac x 3 = \bigg{\lfloor} \frac {x + 1} 3 \bigg{\rfloor} \quad (\text{da } x \equiv 0 \bmod 3)
    \end{align*}
\end{proof}

\noindent Die untere Schranke kann mit folgendem Algorithmus berechnet werden. Für jedes Element von $p$ wird überprüft, ob bei ihm ein neuer monotoner Teilstring beginnt und der Zähler entsprechend erhöht. Die Laufzeit beträgt wegen der for-Schleife $\Theta(n)$.

\begin{algorithm}
    \If{$n = 1$}
    {
        \Return{$0$} \;
    }

    $x \gets 1$ \;
    $incr \gets p_1 > p_0$ \;

    \For{$i \gets 2$ \KwTo $n - 1$}
    {
        \If{$(incr \land (p_{i-1} > p_i)) \lor (\neg incr \land (p_{i-1} < p_i))$}
        {
            $incr \gets \neg incr$ \;
            $x \gets x + 1$ \;
        }
    }

    \Return{$\lfloor (x + 1)/ 3 \rfloor$} \;

    \caption{\textsc{LowerBound}(p)}
\end{algorithm}

\noindent \emph{Ein A*-basiertes Verfahren.} Mit der unteren Schranke wird das Brute-Force Verfahren nun in zwei Aspekten verbessert.

\begin{enumerate}
    \item Anstatt der Warteschlange wird eine Prioritätswarteschlange verwendet, in der die Knoten aufsteigend nach unterer Schranke geordnet sind. Damit werden vielversprechende Pfade früher besucht.
    \item Die kürzeste bisher gefundene Distanz zu einer identischen Permutation wird ständig gespeichert, um das Besuchen unnötiger Knoten zu vermeiden. Ist die untere Schranke eines Knotens größer oder gleich der aktuell kürzesten Distanz, kann dieser nicht zu einem besseren Ergebnis führen.
\end{enumerate}

Aus graphentheoretischer Sicht entspricht das einer Ausführung des A*-Algorithmus auf dem Pancake-Graphen. Der Pseudocode sieht wie folgt aus.

\begin{algorithm}

    $Q \gets$ Priority Queue containing $(\mu(p), n, \textsc{LowerBound}(p))$ \;
    $pre \gets$ Array of Hashmaps of size $n$ \;
    $ubound \gets n$ \;
    $n'$ \;

    \While{$Q \ne \{\}$}
    {
        $(i, m, b) \gets$ \textsc{Dequeue}$(Q)$ \;
        \If{$b \ge ubound$}
        {
            \textbf{break} \;
        }

        \If{$i = 0$}
        {
            \If{$n - m < ubound$}
            {
                $n' \gets m$ \;
                $ubound \gets n - m$ \;
            }
            \textbf{continue} \;
        }

        $s \gets$ \textsc{IthPermutation}$(m, i)$ \;

        \For{$j \gets 0$ \KwTo $m - 1$}
        {
            \If{$\mu(\gamma_j s) \notin pre[m - 2] \land n - m + \text{\textsc{LowerBound}}(\gamma_j s) + 1 < ubound$}
            {
                $pre[m - 2][\mu(\gamma_j s)] \gets i$ \;
                \textsc{Enqueue}$(Q, (\mu(\gamma_j s), m - 1, n - m + \textsc{LowerBound}(\gamma_j s) + 1))$ \;
            }
        }
    }

    \Return{\textsc{ReconstructOperations}$(pre, n', 0)$} \;

    \caption{\textsc{MinOperationsA*}(p)}
\end{algorithm}

Die Knoten werden in $Q$ als 3-Tupels mit Index, Länge und unterer Schranke gespeichert. Beim Einfügen eines neuen Knotens in $Q$ wird dessen untere Schranke auf die Anzahl bisher ausgeführter $\gamma_i$-Operationen plus der von \textsc{LowerBound} geschätzten Zahl plus 1 für die gerade durchgeführte Operation gesetzt. $n'$ speichert die Länge der aktuell besten gefunden identischen Permutation.
\bigskip

\noindent \emph{Branch and Bound.} Zum Vergleich mit dem A*-Verfahren wird noch ein Branch and Bound-Algorithmus vorgestellt. Er nutzt ebensfalls die hergeleitete untere Schranke für $A(p)$. Es wird keine Prioritätswarteschlange über alle Äste der Suche verwaltet, sondern lediglich über die direkten Nachfolger eines Knotens. Die Prioritätswarteschlange $Q$ enthält ein Paar für jeden Nachfolger, bestehend aus dessen unterer Schranke und dem $i$ der $\gamma_i$-Operation, die zu ihm führt. Die Nachfolger sind in $Q$ aufsteigend nach unterer Schranke geordnet und werden in Reihenfolge abgearbeitet. Während A* auf Breitensuche basiert ist, arbeitet dieses Verfahren eher wie Tiefensuche: Bevor der nächste Nachfolgerknoten abgearbeitet wird, wird der aktuelle vollständig abgeschlossen. Das heißt, es wird entweder eine identische Permutation erreicht oder festgestellt, dass keine bessere Lösung als die akutelle Oberschranke existiert. Die aktuelle Oberschranke \emph{ubound} wird rekursiven Aufrufen als Argument mitgegeben. Wenn in der Prioritätswarteschlange nur noch Knoten mit einer größeren Unterschranke als der aktuellen Oberschranke vorhanden sind, wird abgebrochen und die aktuell beste Lösung zurückgegeben. Die Rückgabe besteht aus einem Paar: Ein Array von Wendeoperationen und ein Wahrheitswert, der angibt, ob eine bessere Lösung gefunden wurde. Da der Algorithmus, wie für Tiefensuche üblich, rekursiv arbeitet, wird die Datenstruktur $pre$ zum Speichern des Vorgängers nicht benötigt, das geschieht implizit durch den Stapel rekursiver Aufrufe. Um dennoch zu wissen, welche Knoten bereits besucht wurden, wird ein Array von Hashsets $vis$ angelegt, in dem für jede Permutationslänge die Indizes besuchter Permutationen enthalten sind. Der Pseudocode sieht wie folgt aus.

\begin{algorithm}
    \If{$\mu(p) = 0$}
    {
        \Return{\emph{(empty array, \textbf{true})}} \;
    }
    \If{$\mu(p) \in vis[n - 1]$}
    {
        \Return{\emph{(empty array, \textbf{false})}} \;
    }

    $Q \gets \{(\textsc{LowerBound}(\gamma_i p), i) : 0 \le i \le n - 1\}$ \;
    $res \gets$ empty array \;
    $better \gets$ \textbf{false} \;

    \While{$Q \ne \{\}$}
    {
        $(lbound, i) \gets$ \textsc{Dequeue}$(Q)$ \;
        \If{$lbound \ge ubound$}
        {
            \textbf{break} \;
        }

        (\emph{op}, \emph{found}) $\gets$ \textsc{MinOperationsBnB}$(\gamma_i p, vis, ubound - 1)$ \;
        \If{$\text{found} \land |op| + 1 < ubound$}
        {
            $ubound \gets |op| + 1$ \;
            $res \gets op$ with $i$ appended at front \;
            $better \gets$ \textbf{true} \;
        }
    }

    $vis[n - 1] \gets vis[n - 1] \cup \mu(p)$ \;
    \Return{\emph{(}res, better\emph{)}} \;

    \caption{\textsc{MinOperationsBnB}$(p, vis, ubound)$}
\end{algorithm}

\noindent Beim rekursiven Aufruf muss \emph{ubound} um 1 verringert werden, da durch die $\gamma_i$-Operation auf $p$ nun eine $\gamma_i$-Operation weniger zur Verfügung steht. In \emph{better} wird gespeichert, ob einer der Nachfolgerknoten zu einem neuen besten Ergebnis führen kann.

\subsection{Berechnung der PWUE-Zahl}

Für diese Teilaufgabe wird Dynamische Programmierung verwendet. Man nehme an, ein Array $y$ enthält bei Index $i$ $A(p)$, für jedes $0 \le i \le (k - 1)! - 1$, wobei $|p| = k - 1$ und $\mu(p) = i$. Den Wert von $A(q)$ einer Permutation $q$ der Länge $k$ zu berechnen, ist mithilfe von $y$ einfach.
\begin{align*}
    A(q) = \min_{0 \le i \le k - 1}  y[\mu(\gamma_i q)] + 1
\end{align*}
Die einzige Ausnahme ist $q = I^k$, hier gilt natürlich $A(q) = 0$. Hat man $A(q)$ für jede Permutation der Länge $k$ berechnet, schreibt man diese wieder in $y$ und kann mit $k + 1$ fortfahren. Dies wird solange fortgeführt, bis man $n$ erreicht hat. Während $A(p)$ für jede Permutation der Länge $n$ berechnet wird, kann $P(n)$ als laufendes Maximum aktualisiert werden, und der Index einer Permutation mit $A(p) = P(n)$ gespeichert werden. Zu Beginn enthält $y$ ausschließlich eine 0 bei Index 0, da für $I^1$ 0 Operationen benötigt werden. Bevor $y$ mit den Werten aller Permutationen von Länge $k$ überschrieben werden kann, müssen alle davon berechnet sein, daher werden sie in einem weiteren Array $z$ zwischengespeichert. Hier kann außerdem die Symmetrie des Pancake-Graphen ausgenutzt werden: Nach obiger Formel muss für eine Permutation $k$ Mal $\gamma_i p$ und anschließend $\mu(\gamma_i p)$ berechnet werden. Da $\mu(\gamma_i p^*) = (k - 1)! - \mu(\gamma_i p) - 1$, können die Berechnungen von $\mu$ auf die Hälfte reduziert werden. Für Permutationen der Länge $n$ gilt außerdem, dass $A(p)$ nicht mehr in $z$ gespeichert werden muss, sondern nur ein laufendes Maximum $a_{\max}$ aller $A(p)$ aktualisiert werden muss. Der Ansatz ist im Algorithmus \textsc{Pwue} zusammengefasst. $u$ und $v$ enthalten in der äußeren for-Schleife immer $k!$ bzw. $(k - 1)!$.

\begin{algorithm}
    $y \gets \{0\}, z \gets$ empty array \;
    $u \gets 1, v \gets 1$ \;

    \For{$k \gets 2$ \KwTo $n - 1$}
    {
        $u \gets u \cdot k$ \;

        \For{$i \gets 0$ \KwTo $u / 2$}
        {
            $p \gets$ \textsc{IthPermutation}$(k, i)$ \;

            \For{$j \gets 0$ \KwTo $k$} {
                $l \gets \mu(\gamma_j p)$ \;
                $z[i] \gets \min(z[i], y[l] + 1)$ \;
                $z[u - i - 1] \gets \min(z[u - i - 1], y[v - l - 1] + 1)$ \;
            }
        }

        $z[0] \gets 0$ \;
        swap($y, z$) \;
        $v \gets v \cdot k$ \;
    }
    $u \gets u \cdot n$ \;
    $a_{\max} \gets 0$, \emph{example} $\gets 0$ \;
    \For {$i \gets 0$ \KwTo $u/2$}
    {
        $a_1 \gets n, a_2 \gets n$ \;
        $p \gets$ \textsc{IthPermutation}$(n, i)$ \;
        \For{$j \gets 0$ \KwTo $n$}
        {
            $l \gets \mu(\gamma_j p)$ \;
            $a_1 \gets \min(a_1, y[l])$ \;
            $a_2 \gets \min(a_2, y[v - l - 1])$ \;
        }
        \If{$a_1 > a_{\max}$}
        {
            $a_{\max} \gets a_1$ \;
            \emph{example} $\gets i$ \;
        }
        \If{$a_2 > a_{\max}$}
        {
            $a_{\max} \gets a_2$ \;
            \emph{example} $\gets u - i - 1$ \;
        }
    }

    \Return{\emph{(}$a_{\max}, example$\emph{)}} \;

    \caption{\textsc{Pwue}$(n)$}
\end{algorithm}

\noindent \emph{Anmerkung.} Es wurden auch andere Verfahren in Betracht gezogen, die nicht einfach $A(p)$ für jede Permutation berechnen, sondern die Berechnung für ,,einfacher sortierbare'' Permutationen vermeiden. In der Praxis waren sie jedoch wesentlich ineffizienter als der vorgestellte Algorithmus. Im Folgenden soll eines kurz erläutert werden. Es basiert darauf, dass für eine Permutation $p$ der Länge $n$, sodass $A(p) = P(n)$ jeder kürzeste Pfad zu einer identischen Permutation bei $I^{m}$ endet, wobei $m = n - P(n)$. Für jede Permutation der Länge $k$ mit $m \le k \le n$, die von einem solchen $p$ durch eine Folge von $\gamma_i$-Operationen erreicht werden kann, gilt außerdem, dass ihr kürzester Pfad zu einer identischen Permutation zu $I^m$ oder kleiner führt. Wir nennen im Folgenden die Menge an Permutationen der Länge $k$, deren kürzester Pfad zu $I^m$ oder einer kleineren identischen Permutation führt, $S_k$. Offensichtlich ist $S_n$ genau die gewünschte Menge von Permutationen mit $A(p) = P(n)$. Der Algorithmus arbeitet wie folgt: Man startet mit $S_m$, das aus allen Permutationen der Länge $m$ besteht. Nun definieren wir die Umkehrung von $\gamma_i$: Mit $q = \gamma_{i, r}^{-1} p$ wird die Permutation $q$ der Länge $|p| + 1$ bezeichnet, sodass $\gamma_i q = p$ und $q_i = r$. Der Parameter $r$ ist nötig, da die Umkehrung andernfalls nicht eindeutig wäre. Nun führt man $\gamma_{i, r}^{-1}$ für jede Permutation in $S_m$ aus und speichert für jede Permutation der Länge $m + 1$, die mindestens einmal Ergebnis einer solchen Operation war, wie oft sie Ergebnis einer $\gamma_{i, r}^{-1}$-Operation war. Effizient lässt sich das mit einer Hashmap oder einem balancierten Binärbaum realisieren, wobei ein Zähler für jede betroffene Permutation verwaltet wird. Jede Permutation der Länge $m+ 1$, die $m + 1$ Mal Ergebnis einer $\gamma_{i, r}^{-1}$-Operation war, muss Teil von $S_{m + 1}$ sein und wird dort eingefügt. Nun wird das Verfahren für $S_{m+ 1}$, wiederholt, dann $S_{m + 2}$ usw. bis $n - 1$. Schließlich enthält $S_n$ genau die gewünschte Menge von Permutationen. Bisher wurde angenommen, dass $m = n - P(n)$ bekannt ist, was nicht stimmt, da $P(n)$ berechnet werden soll. Wenn das beschriebene Verfahren aber von einem $k < m$ gestartet wird, ist $S_n$ am Ende leer, da es keine Permutationen der Länge $n$ gibt, deren kürzeste Pfade zu einer identischen Permutation zu $I^k$ oder kleiner führen, für $k < m$. Es wird folglich eine Binärsuche durchgeführt, um das tatsächliche $m$ zu finden. Da nicht für jede Permutation jeder Länge Speicher benötigt wird, und $A(p)$ nur für bestimmte Permutationen berechnet wird, sollten sowohl Laufzeit als auch Speicherverbrauch gegenüber \textsc{Pwue} verbessert sein. Es ergaben sich jedoch folgende praktische Probleme, die insgeamt zu höherer Laufzeit und höherem Speicherverbrauch führen.

\begin{itemize}
    \item Wenn nicht jede Permutation gespeichert wird und kein Array der Länge $n!$ angelegt werden möchte, muss zu $A(p)$ auch $\mu(p)$ gespeichert werden. Während $A(p)$ problemlos in 8 Bits passt, benötigt $\mu(p)$ 64 Bits, soadss der Speicherverbrauch pro Permutation 8 Mal größer wird. Daneben wird, wie bereits erwähnt, eine komplexere Datenstruktur zum Speichern der Zähler benötigt, die einen hohen konstanten bzw. logarithmischen Faktor zur Laufzeit beiträgt.
    \item Das Ausnutzen der Symmetrie des Pancake-Graphen wird weniger effizient, da zu einer Permutation gespeichert werden muss, ob ihr symmetrischer Partner überhaupt in $S_k$ enthalten ist.
    \item Eine Parallelisierung des Verfahrens ist schwierig. Wenn $\gamma_{i, r}^{-1}$-Operationen von mehreren Permutationen gleichzeitig ausgeführt werden, muss die Datenstruktur zum Speichern der Zähler für Permutationen der Länge $k + 1$ gleichzeitig verändert werden. Dagegen kann \textsc{Pwue} vollständig parallelisiert werden.
\end{itemize}

\section{Laufzeitanalyse}

\subsection{Teilaufgabe a)}

Zunächst wird die Laufzeit von \textsc{ReconstructOperations} abgeschätzt. In \textsc{ReconstructOperations} wird die while-Schleife maximal $n - m$ Mal durchgeführt, da $m$ in jeder Iteration um 1 erhöht wird. Die for-Schleife durchläuft jeweils $m + 2$ Iterationen und in jeder wird einmal $\mu(s)$ berechnet, wobei $|s| = m+1$ gilt. Im schlechtesten Fall, wenn $m = 1$, kann die Laufzeit wie folgt beschränkt werden. ($c$ ist eine positive Konstante.)
\begin{align*}
    \sum_{m = 1}^n \sum_{j = 0}^{m+1} \Theta(m \log m)
     & = \sum_{m = 1}^n \sum_{j = 0}^{m+1} cm \log m \\
     & = c \sum_{m = 1}^n (m + 2)m \log m            \\
     & = c \sum_{m = 1}^n m^2 \log m + 2 m \log m    \\
     & \le c \sum_{m = 1}^n n^2 \log n  + 2 n \log n \\
     & = cn^3 \log n + 2cn^2 \log n                  \\
\end{align*}
Eine obere Schranke ist für die Worst Case-Laufzeit ist folglich $O(n^3 \log n)$. Für eine untere Schranke im Worst Case gilt
\begin{align*}
    \sum_{m = 1}^n \sum_{j = 0}^{m+1} cm \log m
     & = c \sum_{m = 1}^n m^2 \log m                                                                                                          \\
     & \ge c \sum_{m = \lfloor n / 2 \rfloor}^{n} \bigg{\lfloor} \frac {n} {2} \bigg{\rfloor} ^2 \log \bigg{\lfloor} \frac n 2 \bigg{\rfloor} \\
     & = c \bigg{\lceil} \frac n 2 \bigg{\rceil} \bigg{\lfloor} \frac n 2 \bigg{\rfloor} ^2 (\log n - \Theta (1))                             \\
     & \ge c \frac {n(n - 1)^2}  8 (\log n - \Theta (1))                                                                                      \\
     & = c \frac {n^3 - 2n^2 + n} 8 (\log n - \Theta (1))
\end{align*}
Nach unten kann die Laufzeit also mit $\Omega(n^3 \log n)$ beschränkt werden. Da obere und untere Schranke übereinstimmen beträgt die Worst-Case Zeitkomplexität von \textsc{ReconstructOperations} $\Theta(n^3 \log n)$.

Um die Laufzeit der drei Algorithmen für Teilaufgabe a) begrenzen zu können, wird eine obere Schranke für die Suchtiefe benötigt. Die beste Schranke wäre natürlich $P(n)$, die Funktion kann aber nicht als geschlossener Ausdruck geschrieben werden. Daher wird folgende Oberschranke für $A(p)$ verwendet.

\begin{lemma}
    $A(p) \le \Big{\lceil} \frac {2n} 3 \Big{\rceil}$
\end{lemma}

\begin{proof}
    Wir betrachten folgenden Algorithmus zum Sortieren von $p$: Die Schritte 1 und 2 werden solange abwechselnd ausgeführt, bis $p$ sortiert ist.
    \begin{enumerate}
        \item Sei $i$ der Index des größten Elements von $p$, das nicht in einem sortierten Suffix liegt. Führe die Operation $\gamma_{i+1}$ aus. Damit wird das größte, noch nicht einsortierte Element nach vorne gebracht.
        \item Führe die Operation $\gamma_{j-1}$ aus, wobei $j$ der kleinste Index eines Elements im sortierten Suffix ist.
    \end{enumerate}
    Da immer das größte Element, das nicht im sortierten Suffix liegt, gewählt wird, wird das sortierte Suffix mit jeder Ausführung dieser zwei Schritte um ein Element vergrößtert. Da gleichzeitig zwei Elemente aus $p$ entfernt werden, besteht $p$ spätestens nach $\lceil 2n / 3 \rceil$ Schritten nur noch aus dem sortierten Suffix.
\end{proof}

Dass die Oberschranke nicht schlecht ist, zeigt das Beispiel $n = 3$. Denn $P(3) = 2$, und die Oberschranke für 3 wäre ebensfalls 2.

Die Gesamtlaufzeit von \textsc{MinOperationsBFS} wird durch die Anzahl besuchter Knoten auf jeder Ebene und die Zeit pro Knoten abgeschätzt. Von Länge $n$ wird genau eine Permutation, $p$, besucht. Davon ausgehend gibt es $n$ Möglichkeiten für eine $\gamma_i$-Operation, also werden maximal $n$ Permutationen der Länge $n - 1$ besucht. Von diesen werden durch $\gamma_i$-Operationen maximal $n(n-1)$ Permutationen der Länge $n - 2$ erreicht. Diese Argumentation lässt sich rekursiv fortführen, es werden also maximal $n! / k!$ Knoten der Länge $k$ besucht. Für kleine $k$ ist $n! / k!$ jedoch größer als $k!$, da es aber nur $k!$ Permutationen der Länge $k$ gibt und kein Knoten doppelt besucht wird, kann die Anzahl besuchter Knoten durch $\min(n! / k!, k!)$ beschränkt werden. Mit Lemma 4 kann $k$ nach unten durch $\lfloor n/3 \rfloor$ begrenzt werden. Summiert man für alle $k$ von $\lfloor n/3 \rfloor$ bis $n$ auf, ergibt sich folgende Oberschranke für die Anzahl besuchter Knoten. Zur Auswertung der Fakultät wird die Stirlingformel verwendet.
\begin{align*}
    \sum_{k = \lfloor n/3 \rfloor}^n \min \bigg ( \frac {n!}{k!}, k! \bigg )
     & \le \sum_{k = \lfloor n/3 \rfloor}^n  \frac {n!} {(n/3)!}
    \\ & \le n \cdot \frac {n!} {(n/3)!}
    \\ & \approx n \cdot
    \frac {\sqrt{2 \pi n} \cdot (n/e)^n} {\sqrt{2 \pi n/3} \cdot (n/3e)^n}
    \\ & = n \cdot
    \frac {n^n / e^n} {\sqrt{1/3} \cdot n^n / (3e)^n}
    \\ & = \sqrt 3 \cdot 3^n \cdot n
\end{align*}

Die Anzahl besuchter Knoten ist also $O(3^n \cdot n)$. Beim Einsetzen des kleinstmöglichen $k = \lfloor n/3 \rfloor$ in der ersten Zeile wurde die Abrundungsfunktion der Einfachheit halber weggelassen, am asymptotischen Verhalten ändert das jedoch nichts.

Für einen Knoten der Länge $k$ ergeben sich zweimal $\Theta(k \log k)$ Schritte: Erstens durch den Aufruf von \textsc{IthPermutation}, und zweitens durch die Berechnung von $\mu(p)$, als die Permutation von ihrem Vorgänger zur Warteschlange hinzugefügt wurde. $\gamma_i$ kann einfach in $\Theta(k)$ Schritten berechnet werden und ist damit nicht relevant. Folglich ergeben sich $\Theta(k \log k)$ Schritte für eine Permutation der Länge $k$. Mit der Oberschranke für die Anzahl besuchter Knoten lässt sich die Worst Case-Laufzeit von \textsc{MinOperationsBFS} durch
\begin{align*}
    O(3^n \cdot n^2 \log n)
\end{align*}
beschränken. Da die Laufzeit exponentiell steigt, ist der Beitrag von $\Theta(n^3 \log n)$ von \textsc{ReconstructOperations} nicht relevant.

Für \textsc{MinOperationsA*} bleibt die Laufzeit grundsätzlich gleich, da im schlechtesten Fall dennoch alle Knoten besucht werden. Für einen Knoten kommt lediglich ein logarithmischer Faktor vom Einfügen in die Prioritätswarteschlange hinzu. Die Größe der Prioritätswarteschlange kann mit der Anzahl besuchter Knoten, $O(3^n \cdot n)$ begrenzt werden. Folglich ist die Worst-Case Zeitkomplexität von \textsc{MinOperationsA*}
\begin{align*}
    O(3^n \cdot n^2 \log n) \cdot \log O(3^n \cdot n)
     & = O(3^n \cdot n^2 \log n) \cdot O(\log (3^n \cdot n)) \\
     & = O(3^n \cdot n^2 \log n) \cdot O(n \log n)           \\
     & = O(3^n \cdot n^3 \log^2 n)
\end{align*}

Die Worst Case-Laufzeit von \textsc{MinOperationsBnB} pro Knoten beträgt $O(n^2)$, da für jeden der maximal $n$ Nachfolgerknoten \textsc{LowerBound} ausgeführt wird. Ebenfalls $O(n)$ Zeit pro Nachfolgerknoten benötigt das mögliche Kopieren von \emph{op} zu \emph{res}. Der Beitrag der Prioritätswarteschlange ist nur $O(n \log n)$, da ein Knoten maximal $n$ Nachfolger hat, und $\mu(p)$ benötigt $\Theta(n \log n)$ Zeit. Im Worst Case beträgt die Laufzeit von \textsc{MinOperationsBnB} also
\begin{align*}
    O(3^n \cdot n^3)
\end{align*}

Im Best Case, wenn die Eingabe eine identische Permutation ist, beträgt die Laufzeit aller drei Verfahren $\Theta(n \log n)$, da einmal $\mu(p)$ berechnet bzw. \textsc{IthPermutation} ausgeführt wird.

\subsection{Teilaufgabe b)}

In \textsc{Pwue} werden für eine Permutation der Länge $k$ $\Theta(k^2 \log k)$ Schritte durchgeführt, da in der dritten verschachtelten for-Schleife in jeder Iteration $\mu(\gamma_i p)$ berechnet wird. Für jedes $2 \le k \le n$ geschieht das für $k! / 2$ Permutationen. Bezüglich \emph{swap} wird eine konstante Laufzeit angenommen, da einfach die Speicheradressen der Arrays getauscht werden können. Summiert man für alle $k$ von $2$ bis $n$ auf, ergibt sich folgende Gesamtlaufzeit.
\begin{align*}
    \sum_{k = 2}^{n} \frac {k!} 2 \Theta(k^2 \log k)
     & = \frac 1 2 \sum_{k = 2}^{n} k! \cdot \Theta(k^2 \log k)                                                     \\
     & \le \frac 1 2 \sum_{k = 2}^{n - 1} (n - 1)! \cdot \Theta(n^2 \log n) + \frac {n!} 2 \cdot \Theta(n^2 \log n) \\
     & \le \frac n 2 \cdot (n - 1)! \cdot \Theta(n^2 \log n) + \frac{n!} 2 \cdot \Theta(n^2 \log n)                 \\
     & = n! \cdot \Theta(n^2 \log n)
\end{align*}
Die Laufzeit ist also durch $O(n! \cdot n^2 \log n)$ nach oben beschränkt. Tatsächlich entspricht das auch der asymptotischen Unterschranke, da
\begin{align*}
    \sum_{k = 2}^{n} \frac {k!} 2 \Theta(k^2 \log k)
    \ge \frac {n!} 2 \cdot \Theta(n^2 \log n)
\end{align*}
ist. Folglich beträgt die Laufzeit von \textsc{Pwue} im Best und Worst Case $\Theta(n! \cdot n^2 \log n)$.

\section{Implementierung}

Die zwei Programme für Teilaufgabe a) und b) werden in C$++$ implementiert. In den Dateien \emph{aufgabe3\_a.cpp} und \emph{aufgabe3\_b.cpp} steht der Quellcode speziell für die Teilaufgaben, in \emph{util.cpp} Funktionen, die von beiden benötigt werden. Zum Kompilieren auf Linux kann einfach \emph{make a} bzw. \emph{make b} im Ordner \emph{aufgabe3} geführt werden. Mit nur \emph{make} werden beide Teilaufgaben kompiliert.
\bigskip

\noindent Grundsätzlich gilt, dass eine Permutation als C$++$ \emph{vector} von \emph{unsigned} repräsentiert wird und meist \emph{p} heißt. Wenn \emph{p} bereits vergeben ist, heißt eine Permutation auch \emph{s}. Die Namensgebung ist eng an die Namensgebung im Pseudocode geknüpft.

\subsection{Hilfsfunktionen}

Hier wird der Inhalt von \emph{util.cpp} beschrieben.
\bigskip

\noindent \verb|size_t ind(vector<unsigned> const &p)|
\smallskip

\noindent Die Funktion \verb|ind| gibt $\mu(p)$ zurück. Wie bereits beschrieben, ist das mit einem Segmentbaum in $\Theta(n \log n)$ Zeit möglich. Es gilt $lgn = \lceil \log_2 n \rceil$ und $m = 2^{\lceil \log_2 n \rceil}$. Der Segmentbaum wird in dem Array \emph{tree} in Heap-Anordnung gespeichert, d. h. die Wurzel liegt bei Index 1, der linke Nachfolger von $i$ bei $2 \cdot i$ und der rechte Nachfolger von $i$ bei $2 \cdot i + 1$. Da der Segmentbaum eine 1 bei Index $i$ stehen hat, wenn Element $i$ bereits auftrat, wird er zu Beginn mit 0 initialisiert. In der for-Schleife steht \verb|z| für den aktuellen Knoten im Segmentbaum, der zu Beginn das Blatt zugehörig zu $p_j$ ist. Für $k$, die Rückgabe von \verb|ind|, gilt bezüglich der äußeren for-Schleife folgende Invariante: Wenn $j = j'$, gilt nach dem Schleifendurchlauf
\begin{align*}
    k = \mu(p)_0 \frac {(n - 1)!} {(n - 1 - j')!} + \mu(p)_1 \frac {(n - 2)!} {(n - 1 - j')!} + \dots + \mu(p)_{j'}
\end{align*}
Bei $j = n - 1$ gilt offensichtlich $k = \mu(p)$. Die Invariante für die Koeffizienten jedes $\mu(p)_i$ wird durch Multiplikation mit \verb|p.size() - j| erhalten. Da $\mu(p)_j$ gleich $p_j$ minus der Anzahl links gelegener, kleinerer Elemente ist, muss nach der Addition von $p_j$ nur noch diese Zahl mithilfe des Segmentbaums abgezogen werden. Dazu wird dieser vom Blatt von $p_j$ beginnend nach oben gelaufen und die Summe des linken Geschwisterknoten, falls man aktuell bei einem rechten Nachfolger steht, abgezogen. Der Wert jedes Knotens auf dem Weg wird um 1 erhöht, da $p_j$ nun selbst vorgekommen ist. Nachdem das für alle $0 \le j \le n - 1$ geschehen ist, wird $k$ zurückgegeben.
\bigskip

\noindent \verb|vector<unsigned> gamma(vector<unsigned> const &p, size_t i)|
\smallskip

\noindent Es wird $\gamma_i p$ berechnet. $(\gamma_i p)_j$ für $j < i$ ist $p_{i - j - 1}$ und für $j > i$ $p_{j + 1}$. Bei Elementen größer als $p_i$ wird 1 abgezogen.
\bigskip

\noindent \verb|size_t ind_gamma(vector<unsigned> const &p, size_t i)|
\smallskip

\noindent Diese Funktion berechnet $\mu(\gamma_i p)$. Da diese Komposition vor allem in Teilaufgabe a) häufig verwendet wird, wurde eine separate Funktion geschrieben, die das Erstellen eines neuen Vektors für $\gamma_i p$ vermeidet. Die Funktionsweise ist identisch zu der von \verb|ind|, nur werden Elemente vor $i$ in entsprechend umgekehrter Reihenfolge bearbeitet und gegebenenfalls 1 von ihrem Wert abgezogen. $x$ bezeichnet in beiden for-Schleifen den Wert von $(\gamma_i p)_j$, ansonsten ist die Namensgebung gleich.
\bigskip

\noindent \verb|void calc_factorial_digits(size_t i, vector<unsigned> &s)|
\smallskip

\noindent Berechnet die Ziffern von $i$ und speichert sie in $s$, wobei die $0!$-Ziffer in an letzer Stelle von $s$ steht. Die Berechnung geschieht analog zur Berechnung der Ziffern einer Zahl im Binärsystem: Zuerst wird durch 1 geteilt, dann durch 2, 3, usw. wobei die jeweiligen Reste den Ziffern von rechts nach links gelesen entsprechen.
\bigskip

\noindent \verb|vector<unsigned> ith_permutation(size_t n, size_t i)|
\smallskip

\noindent Gibt eine Permutation $p$ der Länge $n$ zurück, sodass $\mu(p) = i$. Zunächst wird $p$ als Vektor angelegt und darin die Ziffern von $i$ im fakultätsbasierten Zahlensystem gespeichert. Wie in der Lösungsidee beschrieben enthält der Segmentbaum \emph{tree} hier eine 1 bei Index $j$, wenn der Wert $j$ noch nicht aufgetreten ist, weshalb der Baum mit Einsen initialisiert wird. Bei Bearbeitung $j$-ten Elements wird von der Wurzel ($z = 1$) gestartet, und $p_j$ enthält immer die nötigen links gelegenen Einsen. Im Segmentbaum wird nach rechts gegangen, wenn im linken Nachfolger weniger Einsen als nötig vorhanden sind, oder genauso viele, andernfalls nach links. Der Wert des $j$-ten Elements der Permutation entspricht dann $z - m$, also dem Index des Blatts, bei dem man gelandet ist. Hier werden auf dem Weg nach unten die Werte aller Knoten um 1 reduziert, da $p_j$ danach vorhanden ist.
\bigskip

\noindent \verb|vector<unsigned> rev_and_eat(vector<unsigned> const &p, size_t i)|
\smallskip

\noindent Gibt die Permutation zurück, wenn eine Wende-und-Ess-Operation bei Index $i$ auf $p$ angewandt wird, wie sie im Aufgabenblatt beschrieben ist. Die Funktion wird nur in Teilaufgabe a) zur Ausgabe der entstehenden Permutationen während des Sortierens benötigt.

\subsection{Teilaufgabe a)}

Dem Programm \emph{aufgabe3\_a} kann in der Kommandozeile als Argument \verb|--bfs| oder \verb|--bnb| mitgegeben werden, um \textsc{MinOperationsBFS} bzw. \textsc{MinOperationsBnB} als Algorithms zu verwenden. Standardmäßig wird \textsc{MinOperationsA*} verwendet.
\bigskip

\noindent \verb|vector<unsigned> min_operations_bfs(vector<unsigned> const &p)|
\smallskip

\noindent Die Funktion implementiert das in der Lösungsidee beschriebene Brute-Force Verfahren. Zum Abspeichern des Vorgängers jeder besuchten Permutation wird ein Vektor von \emph{unordered\_map} verwendet, womit gleichzeitig überprüft werden kann, ob ein Knoten schon besucht wurde. Ansonsten entspricht die Implementierung nahezu exakt dem Pseudocode, weshalb sie nicht weiter erläutert wird.
\bigskip

\noindent \verb|vector<unsigned> min_operations_astar(vector<unsigned> const &p)|
\smallskip

\noindent Mit dieser Funktion wird der Algorithmus \textsc{MinOperationsA*} implementiert. Für die Prioritätswarteschlange wird eine \emph{priority\_queue} aus der C$++$ Standardbibliothek verwendet, die wie im Pseudocode 3-Tupels von Index Länge und unterer Schranke enthält. Für eine Tupel wird die \emph{tuple} aus der C$++$ Standardbibliothek verwendet, mit einem \emph{size\_t} und zwei \emph{unsigned}. Da der Datentyp sehr lang ist, wird eine Kurzform \emph{node} für ihn definiert. Dazu gibt es auch eine Vergleichsfunktion \emph{node\_compare} für \emph{node}, da die Prioritätswarteschlange die Tupels absteigend nach Index, Länge und unterer Schranke sortieren würde, sie aber aufsteigend nach unterer Schranke und Länge sortiert werden sollen. Bei gleicher unterer Schranke eine kürzere Permutation zu bevorzugen ist sinnvoll, da man so tendenziell schneller die Suchtiefe vergrößert und durch das Finden einer identischen Permutation eine obere Schranke festlegen kann. \emph{n\_res} entspricht $n'$ aus dem Pseudocode und speichert die Länge der längsten erreichbaren identischen Permutation. Die Überprüfung, ob das oberste Element der Prioritätswarteschlange noch innerhalb der aktuellen Oberschranke liegt, wurde im Vergleich zum Pseudocode in die Abbruchbedingung der while-Schleife verlegt.
\bigskip

\noindent \verb|vector<unsigned> min_operations_bnb(vector<unsigned> const &p)|
\smallskip

\noindent Das Branch and Bound-Verfahren benötigt in der Implementierung zwei Funktionen. In dieser wird das Array von \emph{unordered\_set}, das der rekursiven Funktion \verb|min_operations_bnb_r| als Parameter mitgegeben wird, angelegt. Des Weiteren wird der erhaltene Vektor an $\gamma_i$-Operationen vor der Rückgabe umgekehrt, da die Operationen in der Implementierung im Gegensatz zum Pseudocode hinten an \emph{op} angefügt werden. In Vektoren Elemente vorne anzufügen benötigt $\Theta(n)$ Zeit, während es hinten in amortisiert konstanter Zeit möglich ist.
\bigskip

\noindent \verb|pair<vector<unsigned>, bool> min_operations_bnb_r(| \\
\verb|    vector<unsigned> const &p, vector<unordered_set<size_t>> &vis,)| \\
\verb|    unsigned ubound = UINT_MAX)|
\smallskip

\noindent Diese Funktion ist das rekursive Gegenstück für das Branch and Bound-Verfahren. Die obere Schranke \emph{ubound} muss beim ersten Aufruf nicht als Parameter mitgegeben werden, sondern wird standardmäßig auf einen großen Wert gesetzt. Eine Besonderheit ist, dass für die Prioritätswarteschlange ein Vergleichsoperator \emph{greater} angegeben werden muss, da sie ansonsten absteigend anstatt aufsteigend nach unterer Schranke sortieren würde.
\bigskip

\noindent \verb|vector<unsigned> reconstruct_operations(| \\
\verb|    vector<unordered_map<size_t, size_t>> const &pre, size_t m, size_t i)|
\smallskip

\noindent Gibt die Folge an $\gamma_i$-Operationen zurück, mit denen man zur Permutation $p$ der Länge $m$ mit $\mu(p) = i$ gelangt. $t$ wird vor Rückgabe umgekehrt, da die Operationen in umgekehrter Reihenfolge hinten angefügt wurden.
\bigskip

\noindent \verb|unsigned get_lbound(vector<unsigned> const &p)|
\smallskip

\noindent Gibt die untere Schranke von $\lfloor (x + 1)/ 3 \rfloor$ für die Anzahl benötigter $\gamma_i$-Operationen für $p$, zurück, wobei $x$ die Anzahl monotoner Teilstrings ist. Die Überprüfung, ob bei Index $i$ ein neuer monotoner Teilstring beginnt, wurde in die Funktion \verb|is_increasing| ausgelagert.
\bigskip

\noindent \verb|unsigned get_lbound_gamma(vector<unsigned> const &p, size_t i)|
\smallskip

\noindent Berechnet \textsc{LowerBound}$(\gamma_i p)$. Eine separate Funktion dafür vermeidet das Anlegen eines Vektors für $\gamma_i p$.
\bigskip

\noindent \verb|bool is_increasing(bool incr, unsigned a, unsigned b, unsigned &x)|
\smallskip

\noindent Gibt zurück, ob $a, b$ steigt und erhöht $x$ um 1, falls sich das Steigungsverhalten gegenüber vorher verändert hat.

\subsection{Teilaufgabe b)}

Nach Ausführung des Programms \emph{aufgabe3\_b} muss $n$ als Eingabe gegeben werden.
\bigskip

\noindent \verb|pair<unsigned, size_t> pwue(size_t n)|
\smallskip

\noindent Gibt $P(n)$ sowie den Index einer Permutation der Länge $n$ mit $A(p) = P(n)$ zurück. Die Berechnung wird parallelisiert: Wenn gerade $A(p)$ für alle Permutationen der Länge $k$ bestimmt werden soll, wird das Intervall $[0, k!/2 - 1]$ in \emph{n\_threads} gleich große Teile geteilt und jedem Thread der Index seiner ersten und letzten Permutation mitgegeben. \emph{n\_threads} bezeichnet eine geeignete Anzahl an Threads für den Computer, auf dem das Programm ausgeführt wird. Sie kann mithilfe von \verb|thread::hardware_concurrency()| aus der C$++$ Standardbibliothek festgelegt werden. Die Funktion \verb|pwue| übernimmt in der Implementierung nur das Zuteilen der Threads und Sammeln der Ergebnisse, die eigentlichen Berechnungen finden in den zwei Threadfunktionen statt. Wie im Pseudocode ist die Berechnung in zwei Teile gegliedert: Für $k$ von 2 bis $n - 1$ wird $A(p)$ für jede Permutation in $z$ geschrieben, daher wird in diesem Teil \verb|update_z| als Threadfunktion verwendet. Im zweiten Teil hat jeder Thread eine Rückgabe, das maximale von ihm gefundene $A(p)$ und ein Beispiel dazu. Daher werden die Threads hier mit \verb|async| gestartet, ihre Rückgabe kann dann über die zurückgegebenen \verb|future|-Objekte erhalten werden.
\bigskip

\noindent \verb|void update_z(| \\
\verb|    size_t k, size_t u, size_t v, uint8_t const *const y, uint8_t *const z,| \\
\verb|    size_t i1, size_t i2)|
\smallskip

\noindent Berechnet $A(p)$ für alle Permutationen der Länge $k$ mit $i_1 \le \mu(p) \le i_2 - 1$ und schreibt das Ergebnis in $z$ an Index $\mu(p)$. Da jeder Thread nur auf einen für ihn vorgegebenen Bereich von $z$ zugreift, muss keine Synchronisation stattfinden, was die Parallelisierung sehr effizient macht. Die Namensgebung und Funktionsweise ist genau so wie im Pseudocode, außer dass nicht in jeder Iteration der for-Schleife \verb|ith_permutation| aufgerufen wird, sondern \verb|next_permutation| aus der C$++$ Standardbibliothek zum Erhalten der lexikographisch nächsten Permutation verwendet wird. Die Laufzeit von \verb|next_permutation| beträgt nämlich nur $O(n)$. Asymptotisch ändert das aber nichts.
\bigskip

\noindent \verb|pair<unsigned, size_t> get_max_a(| \\
\verb|    size_t n, size_t u, size_t v, uint8_t const *const y, size_t i1,| \\
\verb|    size_t i2)|
\smallskip

\noindent Gibt das maximale $A(p)$ für Permutationen der Länge $n$ mit $i_1 \le \mu(p) \le i_2 - 1$ zurück, sowie ein Beispiel mit maximalem $A(p)$.

\section{Beispiele}

\subsection{Programmausgabe}

Das Programm für a) gibt neben den Indizes der nötigen $\gamma_i$-Operationen (0-indexiert) auch den aktuellen Stapel nach jedem Sortierschritt aus. Damit kann man nachvollziehen, dass tatsächlich gültige Wendeoperationen ausgeführt wurden. Aus Platzgründen wird das in der Dokumentation nur für \emph{pancake0} abgedruckt. Die Ausgaben stammen von \verb|min_operations_astar|, die anderen zwei Algorithmen geben im Allgemeinen andere, kürzeste Folgen aus. Die Beispiele \emph{pancake8} bis \emph{pancake11} wurden selbst hinzugefügt, wobei versucht wurde, möglichst schwierige Beispiele zu erstellen. ,,Schwierig'' bedeutet nicht unbedingt ein großes $n$, sondern eine hohe Anzahl nötiger Operationen, weil so die Suchtiefe groß wird. Die Beispiele \emph{pancake10} und \emph{pancake11} haben die Form
\begin{align*}
    1, n, 2, n - 1, 3, n - 2, 4, n - 3, \dots, \lfloor n/2 \rfloor + 1
\end{align*}
die meistens eine hohe Zahl an Operationen benötigt (nicht immer, $n = 14$ ist ein Gegenbeispiel). Für $n = 16$ benötigt diese Art ebenfalls 9 Operationen, wie \emph{pancake9}.

\subsubsection*{pancake0}
\begin{lstlisting}[numbers=none]
2 Operationen notwendig. Dazu hinter folgenden Indizes wenden:
4, 3

Index |  p
4     |  3   2   4   5   1   
3     |  5   4   2   3   
      |  2   4   5   
\end{lstlisting}

\subsubsection*{pancake1}
\begin{lstlisting}[numbers=none]
3 Operationen notwendig. Dazu hinter folgenden Indizes wenden:
2, 3, 4
\end{lstlisting}

\subsubsection*{pancake2}
\begin{lstlisting}[numbers=none]
4 Operationen notwendig. Dazu hinter folgenden Indizes wenden:
1, 3, 3, 4  
\end{lstlisting}

\subsubsection*{pancake3}
\begin{lstlisting}[numbers=none]
6 Operationen notwendig. Dazu hinter folgenden Indizes wenden:
10, 4, 5, 2, 2, 4 
\end{lstlisting}

\subsubsection*{pancake4}
\begin{lstlisting}[numbers=none]
7 Operationen notwendig. Dazu hinter folgenden Indizes wenden:
3, 10, 9, 7, 3, 0, 6 
\end{lstlisting}

\subsubsection*{pancake5}
\begin{lstlisting}[numbers=none]
6 Operationen notwendig. Dazu hinter folgenden Indizes wenden:
0, 12, 6, 8, 4, 5  
\end{lstlisting}

\subsubsection*{pancake6}
\begin{lstlisting}[numbers=none]
8 Operationen notwendig. Dazu hinter folgenden Indizes wenden:
6, 9, 8, 3, 0, 4, 8, 0
\end{lstlisting}

\subsubsection*{pancake7}
\begin{lstlisting}[numbers=none]
8 Operationen notwendig. Dazu hinter folgenden Indizes wenden:
2, 2, 5, 9, 3, 10, 9, 5
\end{lstlisting}

\subsection*{pancake8}
\scriptsize \emph{Eingabe:} \verb|14 9 2 12 4 11 5 14 6 3 13 8 10 7 1|
\normalsize
\begin{lstlisting}
8 Operationen notwendig. Dazu hinter folgenden Indizes wenden:
12, 4, 8, 6, 4, 7, 6, 6
\end{lstlisting}

\subsection*{pancake9}
\scriptsize \emph{Eingabe:} \verb|16 15 2 6 10 4 8 12 1 13 16 9 14 7 5 11 3|
\normalsize
\begin{lstlisting}[numbers=none]
9 Operationen notwendig. Dazu hinter folgenden Indizes wenden:
2, 10, 9, 5, 6, 4, 8, 6, 7
\end{lstlisting}

\subsection*{pancake10}
\scriptsize \emph{Eingabe: }\verb|18 1 18 2 17 3 16 4 15 5 14 6 13 7 12 8 11 9 10|
\normalsize
\begin{lstlisting}[numbers=none]
10 Operationen notwendig. Dazu hinter folgenden Indizes wenden:
3, 10, 9, 5, 1, 5, 9, 8, 6, 5
\end{lstlisting}

\subsection*{pancake11}
\scriptsize \emph{Eingabe: }\verb|20 1 20 2 19 3 18 4 17 5 16 6 15 7 14 8 13 9 12 10 11|
\normalsize
\begin{lstlisting}[numbers=none]
11 Operationen notwendig. Dazu hinter folgenden Indizes wenden:
1, 8, 11, 9, 1, 7, 13, 3, 7, 6, 8
\end{lstlisting}

\subsection{Vergleich der drei Algorithmen}

Die drei Verfahren für Aufgabe a) wurden auf alle Beispiele angewandt und jeweils die Laufzeit (in s) sowie die Anzahl besuchter Permutationen gemessen. Diese Zahl wurde durch \emph{pre} bzw. \emph{vis} erhalten.

\begin{table}[H]
    \centering
    \begin{tabular}{c c c c c c c}
        & \multicolumn{2}{c}{\textsc{MinOperationsBFS}} &
        \multicolumn{2}{c}{\textsc{MinOperationsA*}} &
        \multicolumn{2}{c}{\textsc{MinOperationsBnB}} \\
        & Laufzeit & \# Knoten & Laufzeit & \# Knoten & Laufzeit & \# Knoten \\
        \cmidrule{1-7}
        pancake0 & 0,003 & 11 & 0,003 & 11 & 0,003 & 8 \\
        pancake1 & 0,004 & 70 & 0,004 & 62 & 0,003 & 60  \\
        pancake2 & 0,004 & 148 & 0,003 & 118 & 0,004 & 147  \\
        pancake3 & 0,011 & 3063 & 0,010 & 2941 & 0,012 & 2941  \\
        pancake4 & 0,063 & 26544 & 0,050 & 24385 & 0,054 & 23880 \\
        pancake5 & 0,093 & 86718 & 0,059 & 42919 & 0,048 & 28865 \\
        pancake6 & 0,507 & 293320 & 0,423 & 258198 & 0,718 & 263616 \\
        pancake7 & 2,544 & 1056514 & 0,993 & 692598 & 1,973 & 693175 \\
        pancake8 & 0,121 & 83194 & 0,118 & 81564 & 0,209 & 80881 \\
        pancake9 & 2,490 & 1052794 & 2,782 & 1025096 & 4,524 & 1020675 \\
        pancake10 & 34,60 & 9071860 & 25,57 & 8088249 & 45,89 & 8597389 \\
        pancake11 & $-$ & $-$ & 360,2 & 96756054 & 664,2 & 105275870
    \end{tabular}
    \caption{Laufzeit (in s) und Anzahl besuchter Permutationen der drei Algorithmen für Teilaufgabe a)}
\end{table}

\noindent Für die kleinen Beispiele ist die Laufzeit wenig aussagekräftig, hier sieht man aber bereits, dass die zwei verbesserten Verfahren die Anzahl besuchter Knoten bzw. Permutationen deutlich verringern können. Sie liegt in allein Beispielen unter der von \textsc{MinOperationsBFS}. Für größere Beispiele wirkt sich das auch positiv auf die Laufzeit aus. Zwischen \textsc{MinOperationsA*} und \textsc{MinOperationsBnB} lässt sich kein klarer Gewinner ausmachen. \textsc{MinOperationsA*} war meistens schneller, obwohl manchmal mehr Knoten besucht wurden, was möglicherweise am zuätzlichen Aufwand der Rekursion von \textsc{MinOperationsBnB} liegt. Das letzte Beispiel konnte von \textsc{MinOperationsBFS} aufgrund des zu hohen Speicherverbrauchs nicht gelöst werden, auf dem verwendeten PC stehen 5,7 GB effektiv zur Verfügung. Der Speicherverbrauch der anderen zwei Verfahren lag bei ca. 5 GB.

\subsection{Werte von $P(n)$}

Mit dem Programm für Teilaufgabe b) konnte die PWUE-Zahl bis $n = 13$ berechnet werden. Die Ergebnisse sind in folgender Tabelle dargestellt.

\begin{table}[H]
    \centering
    \begin{tabular}{c c l}
        \toprule
        $n$ & $P(n)$ & Beispiel mit $A(p) = P(n)$       \\
        \cmidrule{1-3}
        8   & 5      & 6 3 8 5 2 7 4 1                  \\
        9   & 5      & 9 7 3 8 5 2 6 4 1                \\
        10  & 6      & 10 3 5 9 4 6 8 2 7 1             \\
        11  & 6      & 11 10 4 6 9 3 8 2 7 5 1          \\
        12  & 7      & 12 9 4 11 5 8 3 6 10 2 7 1       \\
        13  & 7      & 13 12 9 4 11 8 3 7 2 6 10 5 1    \\
        14  & 8      & 9 2 12 4 11 5 14 6 3 13 8 10 7 1 \\
        \bottomrule
    \end{tabular}
    \caption{PWUE-Zahlen bis $n = 14$ mit Beispielen}
\end{table}

\noindent Dass $P(14) = 8$ ist, wurde nicht wie die anderen PWUE-Zahlen berechnet, kann aber wie folgt begründet werden. Es gilt $P(n) \le P(n - 1) + 1$ für $n \ge 2$, da jede Permutation der Länge $n$ durch eine Operation in eine Permutation der Länge $n - 1$ umgewandelt werden kann. Des weiteren gilt $P(n) \ge P(n - 1)$. Wäre das nicht der Fall, könnte an eine Permutation der Länge $n - 1$ das Element $n$ hinten anhängen und sie mit weniger Schritten als zuvor sortieren, ein Widerspruch. Gilt also $P(13) = 7$ muss $P(14) = 7$ oder $P(14) = 8$ sein. Da von dem in der Tabelle genannten Beispiel aber mithilfe des Programms für a) überprüft werden kann, dass $A(p) = 8$, muss $P(14) = 8$ gelten.
\bigskip

\noindent \emph{Das tatsächliche Laufzeitverhalten des Programms.} Im Verhältnis zur sehr schlechten asymptotischen Laufzeit von $\Theta(n! \cdot n^2 \log n)$ lief das Programm von Teilaufgabe b) relativ schnell. Zur Berechnung von $P(13)$ sollten nach der theoretischen Abschätzung in der Größenordnung von $13! \cdot 13^2 \cdot \log_2 13 \approx 3,89 \cdot 10^{12}$ Schritte nötig sein. Auf einem Laptop mit dem Prozessor AMD Ryzen 7 3700U (Mobile, weit von der Leistung des Ryzen 7 für Desktop-PCs entfernt) und 8 Threads konnte $P(13)$ in nur !!!!! min berechnet werden. Für $P(12)$ wurden 1 min und 13 s benötigt, für $P(11)$ ca. 5,5 s.

\section{Quellcode}

\subsection{util.cpp}

\lstinputlisting[language=C++]{aufgabe3/util.cpp}

\subsection{aufgabe3\_a.cpp}

\lstinputlisting[language=C++]{aufgabe3/aufgabe3_a.cpp}

\subsection{aufgabe3\_b.cpp}

\lstinputlisting[language=C++]{aufgabe3/aufgabe3_b.cpp}

\begin{thebibliography}{5}
    \bibitem{permutationranking}
    Bonet, B. (2008).
    Efficient Algorithms to Rank and Unrank Permutations in Lexicographic Order. \\
    https://www.aaai.org/Papers/Workshops/2008/WS-08-10/WS08-10-004.pdf

    \bibitem{burntpancakes}
    Cohen, D. S., Blum, M. (1993).
    On the problem of sorting burnt pancakes. \\
    https://www.sciencedirect.com/science/article/pii/0166218X94000093

    \bibitem{discretemath}
    Johnsonbaugh, R. (2017).
    Discrete Mathematics (8. Auflage).
    Pearson Verlag.

    \bibitem{factorial}
    Wikipedia (2022).
    Factorial number system. \\
    https://en.wikipedia.org/wiki/Factorial\_number\_system

    \bibitem{lexicographic}
    Wikipedia (2022).
    Lexicographic order. \\
    https://en.wikipedia.org/wiki/Lexicographic\_order
\end{thebibliography}

\end{document}